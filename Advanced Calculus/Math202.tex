\documentclass[12pt]{article}
\usepackage[letterpaper, portrait, margin=1in]{geometry}
\usepackage{amsmath, amsthm, amssymb, mathrsfs, dsfont}

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\lhead{Darshan Patel}
\rhead{Math 202: Advanced Calculus}
\renewcommand{\footrulewidth}{0.4pt}
\cfoot{\thepage}

\begin{document}

\theoremstyle{definition}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}{Definition}[section]
\newtheorem{example}{Example}[section]

\newcommand{\curl}{\text{curl }}
\renewcommand{\div}{\text{div }}

\title{Math 202: Advanced Calculus}
\author{Darshan Patel}
\date{Fall 2016}
\maketitle


\begin{definition} Function: defined from a set $U$ into $\mathbb{R}^m$ where $U$ is the domain and $\mathbb{R}^m$ is the codomain \end{definition} 
\begin{definition} Range of $F$: actual output of $F$, denoted by $F(U)$ \end{definition}
To study the calculus of vector-valued functions, $F$, we can reduce to studying each coordinate function, $F: U \to \mathbb{R}$. 
\begin{definition} Graph of $F$: $$\{(\vec{x}, F(\vec{x})) | \vec{x} \subset U \} \text{ in } \mathbb{R}^{n + m} $$ \end{definition}
\begin{example} For an old fashion calculus I function: $f(x) = x^2$, its graph lies in $\mathbb{R}^2$. \end{example}
\begin{example} \begin{itemize} 
\item Let $U$: mountain in $\mathbb{R}^3$. At each point of $U$, there is a velocity vector in the direction of flow of melting snow downward. This is a vector-valued function. 
\item Let $T$: Arizona into its temperature at each point. This is a $\mathbb{R}^2 \to \mathbb{R}^1$ function. This is thus a scalar-valued function. \end{itemize} \end{example} 
\begin{definition} Level Set: obtained by setting a vector-valued function equal to a constant \end{definition} 
\begin{definition} Section: intersection of graph with plane \end{definition} 
\begin{example}  \begin{itemize} Let $f(x, y) = y^2 - 4x^2$ where $f: \mathbb{R}^2 \to \mathbb{R}$. Setting it equal to zero, the function is now $y^2 - 4x^2 = 0$. The graph should be a one-dimensional object in $\mathbb{R}^2$. More generally, we can think of $f(x, y) = y^2 - 4x^2$ as a function $f: \mathbb{R}^2 \to \mathbb{R}$ and the graph of $f: \{(x, y, f(x, y))\}$ in $\mathbb{R}^3$ is a surface of two dimensional object in $\mathbb{R}^3$. In $y-z$ plane, we have parabola $z = y^2$. Level curves are hyperbolas on plane $z = c$ with $y$-coordinate $±$ when $x = 0$. This is a hyperbolic paraboloid. 
\item Let $f(x, y, z) = 4x^2 - y^2 + z^2$ where $f: \mathbb{R}^3 \to \mathbb{R}$. The level surface is $4x^2 - y^2 + z^2 = c$ or $4x^2 + z^2 = y^2 + c$. This is an ellipse with increasing major axis as $y$ increases. The graph of $f$ is a hyperboloid of one sheet if $c > 0$, a hyperboloid of two sheets if $c < 0$ and a cone if $c = 0$. \end{itemize} \end{example}

\begin{definition} Usual Euclidean Distance Function on $\mathbb{R}^n$: $$d(\vec{x}.\vec{y}) = \sqrt{(x_1 - y_1)^2 + (x_2 - y_2)^2 + \dots + (x_n - y_n)^2} $$ \end{definition} 
\begin{definition} Open Interval/Disk/Ball: all points within a distance $r > 0$ from a given point $x_0$ in $\mathbb{R}^n$ where $\{\vec{y} | d(\vec{x_0}, \vec{y_0}) < \varepsilon \}$ in $\mathbb{R}^n$; for one dimension, it is an interval; for two dimensions, it is a disk; for three dimensions, it is a ball \end{definition} 
\begin{definition} Open Neighborhood $U$ of $\vec{x_0}$: has the following property: around each point $\vec{u} \in \vec{U}$, there is a disk of some radius $r > 0$ such that $D_r(\vec{u}) \in U$ \end{definition} 
Note: An open disk $D_r(\vec{x_0})$ is an open neighborhood of each point in it. 
\begin{definition} Complement of a Set: given a set $A$ in $\mathbb{R}^n$, the complement is all points in ambient space $\mathbb{R}^n$ that are not in $A$ \end{definition}
\begin{definition} Boundary of a Set: a point is a boundary point of $A$ if every $D_f(b)$ intersects $A$ and $A^c$ \end{definition}
\begin{definition} Closure of a Set: the union of $A$ and the boundary of $A$, denoted by $\bar{A}$ \end{definition} 
Note: By convention, an empty set is open as well as ambient space. \\~\\
A set is closed if its complement is open. Closed sets contain their boundaries. 
\begin{definition} Limit: Let $F: U \to \mathbb{R}^n$ and $x_0 \in \bar{U}$. Then $\lim_{x \to x_0} f(x) = b$ means for every open neighborhood $B$ of $b$, we can find an open neighborhood $A$ of $x$ such that $f(A \cap U) \subseteq B$ \end{definition} 
Note: If you are close enough to $x_0$, then the image under $f$ should be close to $B$. 
\begin{example} Let $f(x) = x^2$. Show $\lim_{x \to 3} f(x) = 9$. \\~\\
We start with an open disk around $B = 9$. $D_r(9)$ is in $\mathbb{R}$, which is $(9 - \varepsilon, 9 + \varepsilon)$. Find $A = D_\delta(3)$. We want $f(x)$ to be close to 9. In other terms, $$|f(x) - 9| < \varepsilon $$ To do so, we have to find where $x$ is close to 3, or $$|x - 3| < \delta $$ $$\begin{aligned} 
|x^2 - 9| &< \varepsilon \\ |(x - 3)(x + 3)| &< \varepsilon \\ |x - 3||x + 3| &< \varepsilon \\ |x - 3| &< \frac{\varepsilon}{|x + 3|} \end{aligned} $$ But $\delta$ is not allowed to depend on the variable $x$. Let's say $\delta < 1$. Then we know that $x > 2$. So $ |x + 3| < 7$. Thus $\frac{\varepsilon}{|x + 3|} > \frac{\varepsilon}{7}$. Choose $\delta = \frac{\varepsilon}{7}$. Then if $|x - 3| < \delta$, we know $|x - 3| < \frac{\varepsilon}{|x + 3|}$ or $|x^2 - 9| < \varepsilon$. \end{example} 
\begin{example} Prove $\lim_{x \to 2} 4x - 1 = 7$. \\
Let $f(x) = 4x - 1$. We want $|f(x) - 7| < \varepsilon$ $$\begin{aligned} |f(x) - 7| &< \varepsilon \\ |4x - 1 - 7| &< \varepsilon \\ |4x - 8| &< \varepsilon \\ 4|x - 2| &< \varepsilon \\ |x - 2| &< \frac{\varepsilon}{4} \end{aligned} $$ This part says that we want $f(x)$ to be closed to alleged value $b = 7$. We do so by keeping $x$ as close as possible to $a = 2$, or $|x - 2| < \delta$. Thus choose $\delta = \frac{\varepsilon}{4}$. To verify this choice of $\delta$, we will be given $|x - 2| < \delta$. Thus $|x - 2| < \frac{\varepsilon}{4}$. Therefore, by cross multiplying, $|4x - 8| < \varepsilon$. This shows that $|f(x) - 7| < \varepsilon$. \end{example}
\begin{example} Prove: $\lim_{x \to 2} x^3 = 8$. \\ 
Let $f(x) = x^3$. We want $|f(x) - b| < \varepsilon$, or $|x^3 - 8| < \varepsilon$. To accomplish this, we keep $x$ as close to $a$, or $|x < 2| < \delta$. $$\begin{aligned} |x^3 - 8| &< \varepsilon \\ |(x - 2)(x^2 + 2x + 4)| &< \varepsilon \\ |x + 2| &< \frac{\varepsilon}{|x^2 + 2x + 4} \end{aligned} $$ We have to get rid of the $x$'s on the right hand side. Thus we will make $\delta < 1$. Given that $|x - 2| < \delta < \frac{\varepsilon}{|x^2 + 2x + 4|}$, then $1 < x < 3$. The minimum for the fraction occurs at the lowest denominator $x = 3$. Thus $\frac{\varepsilon}{|x^2 + 2x + 4|} = \frac{\varepsilon}{19}$. Therefore choose $\delta = \min\{\frac{\varepsilon}{19}, 1\}$. Now we will be given $$|x - 2| < \delta \leq \frac{\varepsilon}{19} \leq \frac{\varepsilon}{|x^2 + 2x + 4|} $$ Cross multiplying will give $$\begin{aligned} |(x - 2)(x^2 + 2x + 4)| &< \varepsilon \\ |x^3 - 8| &< \varepsilon \\ |f(x) - 8| &< \varepsilon \end{aligned} $$ \end{example}
\begin{example} Find $\lim_{(x, y) \to (0, 0)} \frac{(x - y)^2}{x^2 + y^2}$. \\
Try some paths toward $(0, 0)$. \\ On the path $x = 0$, $f(0, y) = \frac{y^2}{y^2} = 1$. Thus the limit is 1 on this path. On the path $y = 0$, $f(x, 0) = \frac{x^2}{x^2} = 1$. Thus the limit is also 1 on this path. On the path $y = x$, $f(x, x) = 0$. The limit is 0 on this path. Since different paths give different limits, the limit does not exist at $(0, 0)$. \end{example} 
Note: If you get different limits on different paths, the two-dimensional limit does not exist. 
\begin{example} Find $\lim_{(x, y) \to (0, 0)} \frac{x^3 - y^3}{x^2 + y^2}$. \\
Let's convert this into polar form. To approach $(0, 0)$, $r \to 0$, which is independent of $\theta$. 
$$\lim_{(x, y) \to (0, 0)} \frac{x^3 - y^3}{x^2 + y^2} = \lim_{r \to 0} \frac{r^3\cos^3(\theta) - r^3\sin^3(\theta)}{r^2} = \lim_{r \to 0} r(\cos^3(\theta) - \sin^3(\theta)) $$ The trig functions cannot approach $\infty$. 
$$0 \leq |r(\cos^3(\theta) - \sin^3(\theta))| \leq |r|(|\cos^3(\theta)| - |\sin^3(\theta)|) \leq 2r $$ 
By Squeeze Theorem, the limit thus goes to zero. \end{example} 

\begin{definition} Partial Derivatives: for a function $f(x_1, \dots, x_n)$ where $f: U \subseteq \mathbb{R}^n \to \mathbb{R}$ and $\vec{x} = (x_1, \dots, x_n)$ $$\frac{\partial f}{\partial x_j} = \lim_{h \to 0} \frac{f(\vec{x} + h\vec{e_j}) - f(\vec{x})}{h} $$ where $\vec{e_j}$ is a standard basis for $\mathbb{R}^n$. This is a derivative in the $x_j$ direction, keeping all other variables constant. \end{definition} 
\begin{definition} Directional Derivative: chosen a unit vector $\vec{u}$ $$D_{\vec{u}}f(\vec{x}) = \lim_{h \to 0} \frac{f(\vec{x} + h\vec{u}) - f(\vec{x})}{h} $$ \end{definition} 
Warning: Partial derivatives may be inadequate to capture the local behavior of functions of several variables. If $U \subseteq \mathbb{R}^n \to \mathbb{R}^m$ is continuous at point $\vec{a} \in U$ then $$\lim_{\vec{x} \to \vec{a}} f(\vec{x}) = f(\vec{a}) $$ Even though the partial derivative at a point may exist, it is possible that it is not continuous at the point. 
\begin{example} Find the partial derivatives of $f(x, y) = \frac{xy}{x^2 + y^2}$ at $(0, 0)$ and the limit as $(x, y) \to (0, 0)$. $$\frac{\partial f}{\partial x}\big|_{(0, 0)} = 0 \\ \frac{\partial f}{\partial y}\big|_{(0, 0)} = 0 $$ 
On the $x$-axis, $y = 0$, the limit is 0. But on the line $y = x$, $f(x, y) = \frac{x^2}{x^2} = 1$. Thus the limit does not exist. \end{example} 
\begin{theorem} Taylor's Theorem for $f(x)$ centered at $a$: $$f(x) = f(a) + f'(a)(x - a) + \dots $$ \end{theorem} 
The best linear approximation to $f(x)$ is $$f(x) = f(a) + f'(a)(x - a)$$ as long as $x$ is close to $a$. The graph of the linear approximation gives a tangent line at point $(a, f(a))$ on the graph of $f$. 
\begin{definition} Linear Transformation: $T: \mathbb{R}^n \to \mathbb{R}^m$ having the properties: \begin{itemize} \item  $T(\vec{x} + \vec{y}) = T(\vec{x}) + T(\vec{y})$ \item $T(c\vec{x}) = cT(\vec{x})$ \end{itemize} \end{definition}
In fact, $T(\vec{x})$ can be represented as matrix multiplication by $m \times n$ matrix. 
\begin{definition} Differentiable: if $f: U \subseteq \mathbb{R}^n \to \mathbb{R}^m$, then $f$ is differentiable at point $\vec{a} \in U$ if we can find the linear transformation $T: \mathbb{R}^n \to \mathbb{R}^m$ such that $$\lim_{\vec{x} \to \vec{a}} \frac{f(\vec{x}) - f(\vec{a}) - T(\vec{x} - \vec{a})}{||\vec{x} - \vec{a}||} = 0$$ \end{definition} 
Another way to say this is to let $$E_{\vec{a}}(\vec{x}) = \frac{f(\vec{x}) - f(\vec{a}) - T(\vec{x} - \vec{a})}{||\vec{x} - \vec{a}||} $$ or $$f(\vec{x}) = f(\vec{a}) + T(\vec{x} - \vec{a}) + E_{\vec{a}}(\vec{x})||\vec{x} - \vec{a}|| $$ where $\lim_{\vec{x} \to \vec{a}} E_{\vec{a}}(\vec{x}) = 0$. 
\begin{theorem} If $f$ is differentiable at $\vec{a}$, then all the partial derivatives $\frac{\partial f}{\partial x_j}$ exist and $T$ is represented as multiplication by matrix $\frac{\partial f}{\partial x_j}(\vec{a})$ where $f(\vec{x}) = (f_1(\vec{x}), f_2(\vec{x}), \dots, f_n(\vec{x}))$ \end{theorem} 
Notation: $\mathcal{D}f(\vec{a})$ is $T$, or the equivalent matrix of partial derivatives as above. \\
Note: $f(x) + T(a)(x - a)$ is the best linear approximation to $f(x)$; here, $T(a)$ is an affine map. 
\begin{theorem} The transformation $T: \mathbb{R}^n \to \mathbb{R}^m$ is represented by the Jacobian matrix $(\frac{\partial f_i}{\partial x_j})$ where $f = (f_1, f_2, \dots)$. \\ Notation: $\mathcal{D}f$ is how this matrix is represented when evaluated at a point of interest. \end{theorem} 
\begin{proof} 
Suppose $\mathcal{D}f(\vec{a}) = \begin{pmatrix} m_{ij} \end{pmatrix}$ and $f = (f_1, f_2, \dots, f_n)$. Then $$ \frac{\partial f_i}{\partial x_j}(a) = \lim_{h \to 0} \frac{f_i(\vec{a} + h\vec{e}_j) - f_i(\vec{a})}{h}$$ Given $f$ is differentiable, use the error form of the derivative on the $i^\text{th}$ coordinate of $f$ with $\vec{x} = \vec{a} + h\vec{e}_j$. Note that $T(\vec{a})(\vec{x} - \vec{a}) = \begin{pmatrix} m_{11} & m_{12} & \dots \end{pmatrix}\begin{pmatrix} 0 \\ \vdots \\ 1 \\ \vdots \\ 0 \end{pmatrix} $. The $i^{\text{th}}$ row of $T(\vec{a})(\vec{x} - \vec{a})$ is $m_{ij}h$: $$f_i(\vec{a} + h\vec{e}_j) = f_i(\vec{a}) + m\vec{e}_jh + E_{\vec{a}}(x)|h|$$ Therefore: $$\frac{\partial f_i}{\partial x_j}(a) = \lim_{h \to 0} \frac{m_{ij}h + E_{\vec{a}}(x)|h|}{h} = m_{ij}\lim_{h \to 0} E_{\vec{a}}(x)\frac{|h|}{h} = m_{ij} $$ As $h \to 0$, $x \to a$. So the error function $E_{\vec{a}}(x) \to 0$. 
\end{proof}

\begin{theorem} If $f$ is differentiable at $x = a$, then $f$ is continuous at $x = a$. \end{theorem} 
\begin{proof} 
Using the definition of derivatives in the error form, show $\lim_{x \to a} f(x) = f(a)$. 
$$\lim_{x \to a} \Big[ f(\vec{a}) + T(\vec{a})(\vec{x} - \vec{a}) + E_{\vec{a}}(x)||\vec{x} - \vec{a}||\Big] = f(\vec{a}) = f(\vec{a}) $$ 

\end{proof}
\begin{theorem} If all partials $\frac{\partial f_i}{\partial x_j}$ exist in the neighborhood of $x = a$, then $f$ is differentiable at $x = a$. The map into $\mathcal{D}f(a)$ is continuous and we say $f$ is $C^1$. \end{theorem} 
\begin{proof} 
We will show that each coordinate function is differentiable assuming that its partial derivatives exist and are continuous in a neighborhood of $\vec{a}$. Let $f: U \subseteq \mathbb{R}^n \to \mathbb{R}$. Do the case where $n = 2$. Then $f = f(x, y)$ and $\vec{a} = (a, b)$. In the definition of derivatives, we will be looking at $$f(x, y) - f(a, b) - \frac{\partial f}{\partial x}(a, b)(x - a) - \frac{\partial f}{\partial y}(a, b)(y - b)$$ and try to show that goes to 0 when divided by $||(x, y) - (a, b)||$. Suppose $f(x, y)$ is within the neighborhood of partial differentiability around $(a, b)$. On the LHS: $$ \begin{aligned} f(x, y) - f(a, b) &= f(x, y) - f(x, b) + f(x, b) - f(a, b) \\ &= f(x, y) - f(x, b) + \frac{\partial f}{\partial x}(t, b)(x - a) - \frac{\partial f}{\partial y}(x, s)(y - b) + \frac{\partial f}{\partial x}(t, b)(x - a) \end{aligned} $$ Subtract the second part from this to arrive at: $$ (\frac{\partial f}{\partial x}(t, b) - \frac{\partial f}{\partial x}(a, b))(x - a) + (\frac{\partial f}{\partial y}(a, s) - \frac{\partial f}{\partial y}(a, b))(y - b) $$ 
Then:$$ \begin{aligned}  &\Big|\frac{(\frac{\partial f}{\partial x}(t, b) - \frac{\partial f}{\partial x}(a, b))(x - a) + (\frac{\partial f}{\partial y}(a, s) - \frac{\partial f}{\partial y}(a, b))(y - b)}{\sqrt{(x - a)^2 + (y - b)^2}}\Big| = \\ &\leq \Big| \frac{\partial f}{\partial x}(t, b) - \frac{\partial f}{\partial x}(a, b)\Big|\frac{|x - a|}{\sqrt{(x - a)^2 + (y - b)^2}} + \Big| \frac{\partial f}{\partial y}(x, s) - \frac{\partial f}{\partial y}(a, b)\Big|\frac{|y - b|}{\sqrt{(x - a)^2 + (y - b)^2}} \\ &\leq \Big| \frac{\partial f}{\partial x}(t, b) - \frac{\partial f}{\partial x}(a, b)\Big| + \Big| \frac{\partial f}{\partial y}(x, s) - \frac{\partial f}{\partial y}(a, b)\Big| \end{aligned} $$ 
As $(x, y) \to (a, b)$, $t$ is squeezed to $a$, $x \to a$ and $s$ is squeezed to $b$. So by the continuity of partials, the limit of the right side is zero. 

\end{proof}
\begin{example} Find the tangent plane at the point $\vec{a} = (3, 1, 10)$ if $f(x, y) = z = x^2 + y^3$. $$\begin{aligned} 
\frac{\partial z}{\partial x} &= 2x \\ \frac{\partial z}{\partial y} &= 3y^2 \\ z &= f(\vec{a}) + \frac{\partial f}{\partial x}(x - x_0) + \frac{\partial f}{\partial y}(y - y_0) \end{aligned} $$ More precisely, we are finding the tangent plane to the graph of $f(x, y)$. That graph is a two-dimensional surface on $\mathbb{R}^3$. Our answer gives a tangent plane as a graph of an affine map. The plane is a graph of $$ z = 10 + 6(x - 3) + 3(y - 1) $$ New POV: Let $f: \mathbb{R}^2 \to \mathbb{R}^1$ and $\mathcal{D}f$ be a $1 \times 2$ matrix. $$ \begin{aligned} \mathcal{D}f &= \begin{pmatrix} \frac{\partial f}{\partial x} & \frac{\partial f}{\partial y} \end{pmatrix} = \begin{pmatrix} 2x & 3y^2 \end{pmatrix} \\ \mathcal{D}f\Big|_{x = a} &= \begin{pmatrix} 6 & 3 \end{pmatrix} \\ \vec{x} - \vec{a} &= \begin{bmatrix} x \\ y \end{bmatrix} - \begin{bmatrix} 3 \\ 1 \end{bmatrix} = \begin{bmatrix} x - 3 \\ y - 1 \end{bmatrix} \\ \mathcal{D}f(\vec{a})\begin{pmatrix} x - 3 \\ y - 1 \end{pmatrix} &= 6(x - 3) + 3(y - 1) \end{aligned} $$ \end{example} 
\begin{example} Find the tangent plane at the point $\vec{a} = (2, 1, 0)$ if $f(x, y, z) = (x + e^z + y, yx^2)$. Let $f: \mathbb{R}^3 \to \mathbb{R}^2$. Thus $\mathcal{D}f$ is a $2 \times 3$ matrix. 
$$\mathcal{D}f = \begin{pmatrix} \frac{\partial f_1}{\partial x} & \frac{\partial f_1}{\partial y} & \frac{\partial f_1}{\partial z} \\ \frac{\partial f_2}{\partial x} & \frac{\partial f_2}{\partial y} & \frac{\partial f_2}{\partial z} \end{pmatrix} = \begin{pmatrix} 1 & 1 & e^z \\ 2xy & x^2 & 0 \end{pmatrix} $$ $$\mathcal{D}f(\vec{a}) = \begin{pmatrix} 1 & 1 & 1 \\ 4 & 4 & 0 \end{pmatrix} $$ Therefore: $$\begin{aligned} f(x, y, z) &= f(\vec{a}) + \mathcal{D}f(\vec{a})(\vec{x} - \vec{a}) \\ &= (4, 4) + \begin{pmatrix} 1 & 1 & 1 \\ 4 & 4 & 0 \end{pmatrix}\begin{pmatrix} x - 2 \\ y - 1 \\ z \end{pmatrix} \\ &= (4 + (x - 2) + (y - 1) + z, 4 + 4(x - 2) + 4(y - 1)) \end{aligned} $$ The graph of $f$ lies in $\mathbb{R}^5$ and is a three-dimensional object. \end{example} 
\begin{example} Find the point on the graph $f(x, y) = 4 - x^2 - y^2$ whose tangent line is parallel to the tangent plane of the graph $g(x, y) = 8 - 2x^2 - 3y^2$ at the point (1, 2, -6). Let $\vec{a} = (1, 2)$. Then: $$g(x, y) = g(\vec{a}) + \frac{\partial g}{\partial x}\Big|_{\vec{a}}(x - 1) + \frac{\partial g}{\partial y}\Big|_{\vec{a}}(y - 2) + \text{Error} $$ $$\frac{\partial g}{\partial x} = -4x \rightarrow \frac{\partial g}{\partial x}\Big|_{\vec{a}} = -4$$ $$\frac{\partial g}{\partial y} = -6y \rightarrow \frac{\partial g}{\partial y}\Big|_{\vec{a}} = -12$$ Then $$L(x, y) = -6 - 4(x - 1) - 12(y - 2) $$ The graph of $L$ is the plane $P$. Recall in $\mathbb{R}^3$, we describe a point on it by $(x_0, y_0, z_0)$ and normal vector $R$. Let $(x_0, y_0, z_0)$ be a ``variable" point on this plane. Then $$R \cdot ((x, y, z) - (x_0, y_0, z_0)) = 0$$ If $R = (a, b, c)$, then $$a(x - x_0) + b(y - y_0) + c(z - z_0) = 0$$ or $$ax + by + cz = d$$ In this example, $z = -6 - 4(x - 1) - 12(y - 2)$. By rearrangement, it is $4(x - 1) + 12(y - 2) + (z - 6) = 0$. So $\vec{a} = (4, 12, 1)$. The general formula for a normal vector to a tangent plane is: $$ \vec{n} = (\frac{\partial f}{\partial x}\Big|_{\vec{a}}, \frac{\partial f}{\partial y}\Big|_{\vec{a}}, -1) $$ For this example, that is $(2x, -2y, -1)$. Since $\vec{n} = k\vec{n_1}$, $$-2x = 4k \\ -2y = 12k \\ 1k = -1 $$ Thus $k = -1$. In conclusion, the point of tangency of graph of $f$ should be (2, 6, -36). \end{example} 
\begin{example} Let $f(x, y) = x^2 + y^2$ and $g(x, y) = -x^2 - y^2 + xy^3$. Why should we say that these two surfaces are tangent at (0, 0, 0)? \\ Note that (0, 0, 0) lies on both graph. Surfaces should meet at the same point, $f(\vec{a}) = g(\vec{a})$ and they should have the same plane at that point. To complete the problem, it suffices to show also that normal vectors are parallel. Take $\vec{a} = (0, 0)$. Then for $f(x, y)$,  $$\vec{n_1} = (\frac{\partial f}{\partial x}\Big|_{\vec{a}}, \frac{\partial f}{\partial y}\Big|_{\vec{a}}, -1) = (0, 0, -1) $$ In the similar matter for $g(x, y)$, $\vec{n_2} = (0, 0, -1)$. Thus the two surfaces are tangent at (0, 0, 0). \end{example} 
\begin{example} Let $f: \mathbb{R}^2 \to \mathbb{R}^3$ where $f(x, y) = (xye^{xy}, x\sin(y), 5xy^2)$. Construct the partial derivatives matrix. $$\mathbb{D}f|_{(x, y)} = \begin{pmatrix} ye^{xy} + xy^2e^{xy} & xe^{xy} + x^2ye^{xy} \\ \sin(y) & x\cos(y) \\ 5y^2 & 10xy \end{pmatrix} $$ When we evaluate this matrix at a given point, we get a $3 \times 2$ numerical matrix from $\mathbb{R}^2 \to \mathbb{R}^3$. The linear approximation to $f$ at point $\vec{a}$ is $f(\vec{a}) + \mathbb{D}f\Big|_{\vec{a}}\cdot(\vec{x} - \vec{a})$. The range of $f$ is a two dimensional surface in $\mathbb{R}^3$. The range of $L$ is a tangent plane to that surface at point $\vec{a}$. The graph of $f$ is in $\mathbb{R}^5$; it is a two dimensional surface in $\mathbb{R}^5$. \end{example} 
\begin{example} Let $f(x, y) = \frac{\sin(x + y)}{x + y}$ and $g(x, y) = \frac{xy}{x^2 + y^2}$. These two functions are not defined at (0, 0). Can we remove the singularity? \\~\\
Try to find $\lim_{(x, y) \to (0, 0)} f(x, y)$. Well, let $x + y = r$. Then $f$ becomes $\frac{\sin(r)}{r}$. As $(x, y) \to (0, 0)$, $r \to 0$. By L'Hopital's Rule, the limit exists and equals 1. Thus singularity can be removed. \\~\\ For g(x, y), different paths towards (0, 0) give different answers. Thus the limit does not exist and therefore singularity cannot be removed. \end{example} 
\begin{example} Is $f(x, y) = ye^x + \sin(x) + (xy)^4$ continuous? \\ Yes because each term is continuous. \end{example} 
\begin{example} Compute $\lim_{(x, y) \to (0, 0)} \frac{(y - x^2)(y - 2x^2)}{y^2 + 2x^4}$. \\ First put $y = 0$ as $x \to 0$. Then $\lim_{(x, 0) \to (0, 0)} \frac{2x^4}{2x^4} = 1$. On any line $y = mx$, the limit is 1. But on a parabola $y = x^2$, the limit is zero. Thus the limit does not exist. \end{example} 
\begin{example} Compute $\lim_{(x, y) \to (1, 2)} \frac{(x - 1)(y - 2)(x + y - 3)}{(x - 1)^2 + (y - 2)^2}$. \\ Let $u = x - 1$, then $u \to 0$. Let $v = y - 2$, then $v \to 0$. Then the limit becomes $\lim_{(u, v) \to (0, 0)} \frac{uv(u + v)}{u^2 + v^2}$. This limit exists and is 0. \end{example} 

Let $C$ be a curve on an interval in $\mathbb{R} \to \mathbb{R}^n$. 
\begin{definition} $c(t)$: a $1 \times 1$ column vector \end{definition} 
\begin{definition} Parametrized Curve: the range of $c$ in $\mathbb{R}^n$ \end{definition} 
\begin{definition} Derivative $\mathds{D}_c$: $c'(t)$, a $n \times 1$ column vector \end{definition} 
To find the derivative of a curve, differentiate each coordinate with respect to $t$. \\~\\ If $C$ is continuous, then it is differentiable; it is also smooth if $c'(t) \neq 0$. \\~\\
Geometric Interpretation: $$c'(t) = \lim_{h \to 0} \frac{c(t_0 + h) - c(t_0)}{h}$$ In the limit, $c'(t)$ becomes a tangent vector to the curve. \\~\\
Physical Interpretation: $c'(t)$ is a velocity vector at point $c(t_0)$ on the curve. \\~\\ The linear approximation to $c(t)$ at $t_0$ is: $$c(t_0) + c'(t_0)(t - t_0)$$ This contrasts with $f: A \subseteq \mathbb{R}^n \to \mathbb{R}$ where $\mathds{D}f_{\vec{a}}$ is a $1 \times n$ row vector, called a gradient, $\nabla f$, which is a vector of partial derivatives. 
\begin{theorem} Chain Rule: Let $g: U \subseteq \mathbb{R} \to \mathbb{R}^m$ and $f: V \subseteq \mathbb{R}^m \to \mathbb{R}^p$, assuming $g(U) \subseteq V$. Suppose $g$ is differentiable at $a \in U$. Let $\mathds{D}g(a) = M$. Suppose $f$ is differentiable at $b \in g(a)$. Let $\mathds{D}f(b) = N$. Then $M$ is a $m \times n$ matrix and $N$ is a $p \times m$ matrix. Moreover, $f\circ g: U \subseteq \mathbb{R}^n \to \mathbb{R}^p$ is differentiable at $a$ and $\mathds{D}(f\circ g)(a) = NM$. \end{theorem} 
\begin{example} Let $f(s, t) = (s^2 - t^2)$ and $g(r, \theta) = (r\cos(\theta), r\sin(\theta))$. Then $$\begin{aligned} \mathds{D}f &= \begin{pmatrix} 2s & -2t \\ 2t & 2s \end{pmatrix} \\ \mathds{D}g &= \begin{pmatrix} \cos(\theta) & -r\sin(\theta) \\ \sin(\theta) & r\cos(\theta) \end{pmatrix} \\ \mathds{D}(f \circ g)(r, \theta) &= \begin{pmatrix} 2s & -2t \\ 2t & 2s \end{pmatrix}\begin{pmatrix} \cos(\theta) & -r\sin(\theta) \\ \sin(\theta) & r\cos(\theta) \end{pmatrix} \end{aligned} $$ 
Recall that if $F(f \circ g)(r, \theta) = (F_1, F_2)$, then $\mathds{D}F = \begin{pmatrix} \frac{\partial F_1}{\partial r} & \frac{\partial F_1}{\partial \theta} \\ \frac{\partial F_2}{\partial r} & \frac{\partial F_2}{\partial \theta} \end{pmatrix}$ and $\frac{\partial F}{\partial r} = \frac{\partial F_1}{\partial s} \cdot \frac{\partial s}{\partial r} + \frac{\partial F_1}{\partial t}\cdot \frac{\partial t}{\partial r}$. \end{example} 
\begin{proof} Idea: By linear approximation, $$\overbrace{g(\vec{x})}^{(1)} = g(\vec{a}) + M(\vec{x} - \vec{a}) = \text{error}_1$$ $y = g(x)$, $b = g(x)$. By linear approximation, $$\overbrace{f(y)}^{(2)} = f(b) + N\overbrace{(y - b)}^{*} + \text{error}_2$$ From (1) says $$y - b = M(\vec{x} - \vec{a}) + \text{error}$$ Put this in for $*$ in (2) $$ (f \circ g)(\vec{x}) = (f \circ g)(\vec{a}) + N(M(\vec{x} - \vec{a}) + \text{error}_1) + \text{error}_2$$ Simplified, this becomes $$ (f \circ g)(\vec{x}) = (f \circ g)(\vec{a}) + NM(\vec{x} - \vec{a}) + \overbrace{N(\text{error}_1) + \text{error}_2}^{\text{error}_3}$$ If we can show that $\frac{\text{error}_3}{||\vec{x} - \vec{a}||} \to 0$, then this proves that $\mathds{D}(f \circ g)(\vec{a}) = NM$. \end{proof} 
\begin{definition} Let $f: U \subseteq \mathbb{R}^n \to \mathbb{R}$ and $c: I \subseteq \mathbb{R} \to \mathbb{R}^n$ where $c(I) \subseteq U$. Then $\mathds{D}f$ at a given point $b$ is a $1 \times n$ row vector called the gradient $$\nabla F\Big|_b = \Big(\frac{\partial f}{\partial x_1}, \dots, \frac{\partial f}{\partial x_n}\Big) \text{ at } b$$ $\mathds{D}(c)$ is a column which is written as $c'(t)$. Then we say that $$\mathds{D}(f \circ c(t)) = \nabla f\Big|_{c(t)} \cdot c'(t)$$ \end{definition} 
Recall that directional derivative of $f$ in direction of a unit vector was defined as: $$\mathds{D}f_{\vec{u}}(\vec{a}) = \lim_{h \to 0} \frac{f(\vec{a} + h\vec{u}) - f(\vec{a})}{h}$$ 
\begin{theorem} If $f$ is differentiable at point $a$, then all of its directional derivatives exist and directional derivative $$\mathds{D}f_{\vec{u}}(\vec{a}) = \nabla f|_{\vec{a}} \cdot \vec{u}$$ \end{theorem} 
\begin{proof} Let $c(t) = \vec{a} + t\vec{u}$, an affine function where $t \in \mathbb{R}$, parameterize a line through point $c(0) = a$ in the direction of unit vector $\vec{u}$. $$c(t) = (a_1, \dots, a_n) + t(u_1, \dots, u_n)$$ Then $c'(t) = \vec{u}$. Then $$\mathds{D}(f \circ c(t))(0) = \nabla f\Big|_{c(0)} \cdot c'(0) = \nabla f\Big|_{\vec{a}} \cdot \vec{u} $$ Let's take our composition of function to be $F(t) = f \cdot c(t)$. Then by linear approximation, $$F(t) = F(0) + (\mathds{D}F(0))\cdot t + \text{error} $$ This is $$\begin{aligned} \lim_{t \to 0} \frac{F(t) - F(0)}{t} &= \mathds{D}F(0) \\ &= \lim_{t \to 0} \frac{f(c(t)) - f(c(0))}{t} \\ &= \lim_{t \to 0} \frac{f(\vec{a} + t\vec{u}) - f(\vec{a})}{t} \end{aligned} $$ which by definition is directional derivative. \end{proof} 
Properties of Gradients: \begin{enumerate} 
\item $\nabla F(\vec{a})$ gives the direction of fastest increase of $F$ from point $\vec{a}$. \begin{proof} Point $a$ is fixed and we want to maximize $\mathds{D}F|_{\vec{u}}(\vec{a})$ as a function of $\vec{u}$. Look at $$\nabla F\Big|_{\vec{a}} \cdot \vec{u} = ||\nabla F\Big|_{\vec{a}}|| \cdot ||\vec{u}|| \cos(\theta)$$ where $\theta$ is the angle between $\nabla F$ and $\vec{u}$. Note that $||\vec{u}|| = 1$. Also, $\cos(\theta)$ is maximum when $\theta = 0$. Thus $\vec{u} = \frac{\nabla F}{||\nabla F||}$ at $\vec{a}$ and the value of the directional derivative in this direction is $||\nabla F|_{\vec{a}}||$. \end{proof} 
\item Consider a level set defined by $f(x_1, \dots, x_n) = k$. If $n = 2$, the level set is a curve in $\mathbb{R}^2$. If $n = 3$, the level set is a surface in $\mathbb{R}^3$. Let $a$ be a point on this level. Then $\nabla F|_a$ is orthogonal to the level set containing the point $a$ at the point $a$. \begin{proof} Take any differentiable curve $c(t)$ passing through point $a$ ($c(t_0) = a$) and staying on that same level ($f(c(t_0)) = k$) for all $t$. Then $$\overbrace{\nabla F|_a}^{\text{gradient}} \cdot \overbrace{c'(t_0)}^{\text{direction of curve = tangent vector to curve}} $$ This is the derivative of the composite function $F(t) = f(c(t))$. Hence $f(c(t)) = k$ for all $t$ and so $\nabla F|_a \cdot c'(t_0) = 0$. \end{proof} \end{enumerate}
\begin{example} Find a tangent to the level set of $f(x, y, z) = x^2 + 2y^2 + 3z^2$ at the point $P(2, -1, -1)$. \\~\\ Level = $f(P) = 9$. Thus the level set is $x^2 + 2y^2 + 3z^2 = 9$, which is an ellipsoid surface in $\mathbb{R}^3$. Here we want a tangent plane. $$\nabla F = (2x, 4y, 6z) \to \nabla F\Big|_p = (4, -4, -6) $$ 
Thus the tangent plane is $$2(x - 2) - 2(y + 1) - 3(z + 1) = 0$$ Old method: We can think of level set as a graph of $g(x, y)$. Then $g(x, y) = z = -\sqrt{\frac{9 - x^2 - 2y^2}{3}}$. The sign is determined by the $z$-coordinate of $P$. The linear approximation of $g$ needs: $$\begin{aligned} \frac{\partial g}{\partial x} &= \frac{x}{\sqrt{3}\sqrt{9 - x^2 - 2y^2}} \to \frac{\partial g}{\partial x}\Big|_P = \frac{2}{3} \\ \frac{\partial g}{\partial y} &= \frac{2y}{\sqrt{3}\sqrt{9 - x^2 - 2y^2}} \to \frac{\partial g}{\partial y}\Big|_P = -\frac{2}{3} \end{aligned}  $$ Thus the linear approximation becomes $$g(p) + (\frac{2}{3}, -\frac{2}{3})(x - 2, y + 1) = -1 + \frac{2}{3}(x - 2) - \frac{2}{3}(y + 1)$$ \end{example}  
\begin{theorem} Clairout's Theorem: Suppose that $f$ is a $C^2$ function in a neighborhood $U$ of $\vec{a} \in \mathbb{R}^2$, or $f: U \to \mathbb{R}$ where $f(x, y)$ is a real number: $$\frac{\partial^2 f}{\partial y \partial x}\Big|_{\vec{a}} = \frac{\partial^2 f}{\partial x \partial y}\Big|_{\vec{a}} $$ \end{theorem} 
\begin{theorem} Taylor's Theorem in One Variable: Let $f(x)$ be a function where at $x = a$, it is $(n - 1)$ times continuously differentiable.Then: $$f(x) = f(a) + f'(a)(x - a) + \frac{1}{2!}f''(a)(x - a)^2 + \dots + \frac{1}{n!}f^{n}(a)(x - a)^{n} + R_{n}(x, a) $$ $R_{n}(x, a)$ should be small even when denoted by $(x - a)^n$. $$\lim_{x \to a} \frac{R_{n}(x - a)}{(x - a)^{n}} = 0$$ assuming $f$ is $C^2$ in the neighborhood of $a$.\end{theorem} 
There are several forms for this remainder: $$R_n(x, a) = \frac{1}{(n + 1)!}f^{n + 1}(c)(x - a)^{n + 1}$$ where $c$ is some point between $x$ and $a$. \\~\\ Integral Form: $$R_n(x, n) = \frac{1}{n!}\int_a^x f^{n + 1}(t)(x - t)^n \, dt $$ 
How does this work out for $f: U \subseteq \mathbb{R}^n \to \mathbb{R}^m$? Assume the line joining $\vec{a}$ to $\vec{x}$ lies in $U$ and $f$ is $C^3$ on $U$. Then $l(t) = \vec{a} + t\vec{h}$ where $\vec{h} = (\vec{x} - \vec{a}) = (h_1, \dots, h_n)$. Let $g(t) = f(\vec{a} + t\vec{h})$ where $g: [0, 1] \to \mathbb{R}$. Applying Taylor's Theorem in one variable to $g(t)$: $$f(x) = f(a) + \underbrace{\nabla \cdot \vec{h}}_{\sum_{i = 1}^n f_{x_i}(\vec{a})h_i} + \frac{1}{2} \sum_{1 \leq i, j \leq n} \frac{\partial^2 f}{\partial x_i \partial x_j} h_ih_j + R_2(\vec{x}, \vec{a}) $$ where $\lim_{\vec{x} \to \vec{a}} \frac{R_2(\vec{x}, \vec{a})}{|| \vec{x} - \vec{a}||^2} \to 0$. Chain Rule shows that $g'(t) = \mathds{D}f(t)\cdot \vec{h} = \nabla f(t) \cdot \vec{h}$. 
\begin{definition} Saddle Point: a point where the first derivative either does not exist or is 0 \end{definition} 
\begin{theorem} These are candidates for relative extrema or saddle (relative max in some direction, relative min in other direction) \end{theorem} 
Idea of this theorem: If we take a section keeping all other variables other than $x_i$ constant, we have relative extrema for that one variable. So $\frac{\partial f}{\partial x_i} = 0$ or does not exist. 
\begin{example} Let $f(x_1, x_2) = e^{-x_1^2}\cos x_2$ be centered around $a = (0, 0)$. $$\begin{aligned} 
e^x &= 1 + x + \frac{1}{2}x^2 \\ e^{-x_1^2} &= 1 - x_1^2 + O(x_1^4) \\ \cos x &= 1 - \frac{x_2}{2!} + \frac{x^4}{4!} + \dots \\ \cos x_2 &= 1 - \frac{x_2^2}{2!} + O(x_2^4) \end{aligned} $$ $O(x^4)$ means that the limit behavior as $x \to 0$ is like a constant times $x^4$. Thus $$f(x_1, x_2) = (1 - x_1^2)(1 - \frac{1}{2}x_2^2) + \text{error of degree 4} $$ $$f(x_1, x_2) = 1 - x_1^2 - \frac{1}{2}x_2^2 + \text{error of degree 4} $$ It follows that $\nabla f(0, 0) = (0, 0)$. Moreover, the Hessian matrix $H = \Big(\frac{\partial^2 f}{\partial x_i \partial x_j}\Big)$ here is $$H = \begin{pmatrix} -2 & 0 \\ 0 & -1 \end{pmatrix} $$ Thus $(0, 0)$ is a critical point, i. e $\nabla f = 0$. In fact, $f(0, 0) = 1$. \end{example} 
\begin{definition} Quadratic Form: a function of the form $\sum_{1 \leq i, j \leq n} ax_ix_j$, arranged so that coefficient of $x_ix_j$ = coefficient of $x_jx_i$ for $i \neq j$. For example, $2x_1x_2 + 3x_2x_1 = \frac{5}{2}x_1x_2 + \frac{5}{2}x_2x_1$. They can be represented by matrix multiplication $A = (a_{ij})$, a symmetric matrix. Let $x = (x_1, x_2, \dots, x_n)$. Then $$Q(x_1, x_2, \dots, x_n) = \begin{pmatrix} x_1 & x_2 & \hdots & x_n\end{pmatrix} A \begin{pmatrix} x_1 \\ x_2 \\ \vdots \\ x_n \end{pmatrix} $$ \end{definition} 
In the previous example, matrix $H$ represents quadratic form: $$\begin{pmatrix} x_1 & x_2 \end{pmatrix} \begin{pmatrix} -2 & 0 \\ 0 & -1 \end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \end{pmatrix} = \begin{pmatrix} -2x_1 & 0 \\ 0 & -x_2 \end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \end{pmatrix} = -2x_1^2 - x_2^2 $$ 
In Taylor's Theorem around a critical point: $$f(x) = f(a) + \frac{1}{2}Q(h_1, h_2, \dots, h_n)$$ where $Q$ is represented by Hessian matrix (second derivative matrix) and $(h_1, h_2, \dots, h_n) = (x_1, x_2, \dots, x_n) - (a_1, a_2, \dots, a_n)$. \\~\\ Note: \begin{enumerate} 
\item $Q$ is positively definite if $Q(x_1, x_2, \dots, x_n) \geq 0$ and only is 0 when $\vec{x} = 0$
\item $Q$ is negatively definite if $Q(x_1, x_2, \dots, x_n) \leq 0$ and only is 0 when $\vec{x} = 0$
\item $Q$ is indefinite if sometimes positive and sometimes negative \end{enumerate} 
Let $Q$ be the quadratic form associated to the Hessian matrix in Taylor's Theorem at a critical point. If $Q$ is positively definite, relative minimum. If $Q$ is negatively definite, relative maximum. If $Q$ is indefinite, saddle point. 
\begin{theorem} Let $H = \begin{pmatrix} a & b \\ b & d \end{pmatrix}$, $Q(x_1, x_2) = ax_1^2 + bx_1x_2 + bx_2x_1 + dx_2^2 = ax_1^2 + 2bx_1x_2 + dx_2^2$ \\~\\ If $a \neq 0$, $$\begin{aligned} Q(x_1, x_2) &= a(x_1^2 + \frac{2b}{a} x_1x_2) + dx_2^2 \\ &= a(x_1 + \frac{b}{a}x_2)^2 + (d - \frac{b}{a})x_2^2 \\ &= a\Big[ (x_1 + \frac{b}{a}x_1)^2 + (\frac{ad - b^2}{a^2})x_2^2\Big] \end{aligned} $$ 
If $a > 0$ and $\det H > 0$, the critical point is a relative minimum. If $a < 0$ and $\det H > 0$, the critical point is a relative maximum. If $\det H < 0$, the critical point is a saddle point. \end{theorem} 
\begin{theorem} Extreme Value Theorem: Suppose $A$ is a closed and bounded set in $\mathbb{R}^n$. If $f: A \to \mathbb{R}^m$ is continuous, then $f$ takes a maximum and minimum on $A$. \end{theorem} 
$A$ is closed if $A$ contains all of its boundary points. $A$ is bounded if $A$ can be contained within a suitably large domain. (Note: a bounded set can be open.) \\~\\ If $f$ is sufficiently differentiable, then (absolute) extrema occur either at critical points (inside region $A$) or at points on boundary. For extrema on boundary, we will review method of Lagrange multipliers. 
\begin{example} What is the nature of the critical points of the function $f(x, y) = x^3 + y^2 - 6xy + 6x + 3y$?  $$\begin{aligned} f_x &= 3x^2 - 6y + 6 \\ f_y &= 2y - 6x + 3 \\ 3x^2 - 6y + 6 &= 0 \\ 2y - 6x + 3 &= 0 \\ y &= 3x - \frac{3}{2} \end{aligned} $$ Substituting back, $$\begin{aligned} 3x^2 - 6(3x - \frac{1}{2}) + 6 &= 0 \\ 3x^2 - 18x + 15 &= 0 \\ 3(x^2 - 6x + 5) &= 0 \\ 3(x - 1)(x - 5) &= 0 \\ x = 1&, y = \frac{3}{2} \\ x = 5&, y = \frac{27}{2} \\ f_{xx} &= 6x \\ f_{yy} &= 2 \\ f_{xy} &= 6 \end{aligned} $$ For the first point, $$H = \begin{pmatrix} 6 & -6 \\ -6 & 2 \end{pmatrix} $$ Because the determinant is negative, the point is a saddle point. For the second point, $$ H = \begin{pmatrix} 30 & -6 \\ -6 & 2 \end{pmatrix} $$ The determinant is positive so the point is a minimum. \end{example} 
\begin{definition} Quadratic Form: $Q(x_1, x_2, \dots, x_n) = \sum_{1 \leq i, j \leq n} a_{ij}x_ix_j$. This is a symmetric matrix where $a_{ij} = a_{ji}$. In Taylor's approximation, $f(\vec{x}) = f(\vec{a}) + \nabla f \cdot (\vec{x} - \vec{a}) + \frac{1}{2}Q(\vec{x}, \vec{a})$ where $\nabla f(\vec{a}) = 0$ at a critical point and the matrix of $Q$ is $\Big( \frac{\partial^2 f}{\partial x^2}\Big)$. \end{definition}
Test for Quadratic Form: \begin{itemize} 
\item if positive definite, diagonal determinants are all positive and thus relative minimum 
\item if negative definite, diagonal determinants alternate starting with $M_1 < 0$ and thus relative maximum
\item if indefinite, saddle point \end{itemize} 
Explain intuitively the relation between determinants and solution of quadratic form. We assume that the quadratic form can be diagonalized. Change of variable means a new shape for $Q$. Thus if $Q \sim \begin{pmatrix} \lambda_1 & 0& 0 \\ \vdots & \ddots & \vdots \\ 0 & 0 & \lambda_n \end{pmatrix}$, then $\tilde{Q} = \lambda_1y_1^2 + \lambda_2y_2^2 + \dots + \lambda_ny_n^2 \geq 0$. 
\begin{example} 
Find the plane tangent to level surface of $f(x, y, z) = x^3 + z^2 + 4xy - 5yz^2$ at $P(2, 3, 1)$. \\~\\
At (2, 3, 1), the level set is $f(x, y, z) = 18$. We also know that $\nabla f(P) \bot $ level set. Thus $$\begin{aligned} \nabla f(x, y, z) &= (3x^2 + 4y, 4x - 5z^2, 2z - 10yz) \\ \nabla f(P) &= (24, 3, -28) \end{aligned} $$ Thus the plane tangent to the level surface is $$24(x - 2) + 3(y - 3) - 28(z - 1) = 0$$ 
\end{example}
\begin{example} Find the plane tangent to the graph of $g(x, y) = x^2 + xy + y^2$ at (2, 1). \\~\\
Let $z = x^2 + xy + y^2$. Then $x^2 + xy + y^2 - z = 0$. Let's call it $f(x, y) = x^2 + xy + y^2 - z$. Thus here, we are looking for a plane tangent to the level set at level 0. $$\nabla f(2, 1, 11) = (13, 4, -1)$$ Then the equation of the tangent plane is $$13(x - 2) + 4(y - 1) - (z - 11) = 0$$ Alternative Method: Surface to graph of $g(x, y)$ approximated by a linear approximation is $$g(\vec{a}) + \nabla g(\vec{a})(x - 2)(y - 1) = 11 + (13, 4)(x - 2, y - 1) = 11 + 13(x - 2) + 4(y - 1) $$ \end{example} 
\begin{example} What is the tangent hyperplane to $x^2 + y^2 + z^2 + w^2 - xyzw = 9$ at $P(1, -1, 2, 3)$? \\~\\ This is a three dimensional object in $\mathbb{R}^4$ or a hypersurface. The tangent hyperplane will be a level set of function $F(x, y, z, w) = x^2 + y^2 + z^2 + w^2 - xyzw$ at level 9. $$\begin{aligned} \nabla F &= (2x + yzw, 2y + xzw, 2z + xyw, 2w + xyz) \\ \nabla F(P) &= (-4, 4, 1, 4) \end{aligned} $$ Thus the equation of the tangent hyperplane is $$-4(x - 1) + 4(y + 1) + (z - 2) + 4(w - 3) = 0$$ \end{example} 
Motivation for Lagrange Multipliers: Let $f$ be a continuous real-valued function on a closed, bounded domain in $\mathbb{R}^n$ and takes on absolute extremes. For example, $f = x + y$ on a region in $\mathbb{R}^2$ contained in the ellipse $9x^2 + 16y^2 = 25$. Inside the ellipse, absolute extremas occur as a relative extrema ($\nabla f = 0$). No extreme points in this example. We want a method to find extremas of $f$ when it is constrained to the curve $g(x, y) = 9x^2 + 16y^2 = 25$. \\~\\ Idea: Extrema for a function $f$ when constrained to $g$ = constant occurs when $\nabla f = \lambda \nabla g$. $$\begin{aligned} \nabla f &= (1, 1) \\ \nabla g &= (18x, 32y) \\ (1, 1) &= \lambda(18x, 32y) = 2\lambda(9x, 16y) \end{aligned}$$ Whenever $\lambda \neq 0$, we have $\frac{1}{2\lambda} = k$. So $k(1, 1) = (9x, 16y)$. Therefore, $x = \frac{k}{9}$ and $y = \frac{k}{16}$. Plugging this back in $9x^2 + 16y^2 = 25$ gives $9(\frac{k}{9})^2 + 16(\frac{k}{16})^2 = 25$. Therefore, $k = \pm 12$. If $k = 12$, $x = \frac{12}{9} = \frac{4}{3}$, $y = \frac{12}{16} = \frac{3}{4}$ and is a max since $f(\frac{4}{3}, \frac{3}{4}) = \frac{25}{12}$. If $k = -12$, $x = -\frac{4}{3}$ and $y = -\frac{3}{4}$ and $f(-\frac{4}{3}, -\frac{3}{4}) = - \frac{25}{12}$ which is a min. 
\begin{theorem} Lagrange Multiplier Theorem: Let $g_1, g_2, \dots, g_m$ be in $U \subseteq \mathbb{R}^n \to \mathbb{R}^m$ and $C^1$. Suppose there's a region $S$ defined by equations $$\begin{aligned} g_1(x_1, x_2, \dots, x_n) &= k_1 \\ g_2(x_1, x_2, \dots, x_n) &= k_2 \\ &\vdots \\ g_m(x_1, x_2, \dots, x_n) &= k_m \end{aligned} $$ Suppose $f\Big|_S$ ($f$ on domain $S$) has a relative extrema at $P$. Then $f$: neighborhood of $P \subseteq S \bigcap U \to R$, where $f$ is $C^1$. If $\nabla g_1(P), \nabla g_2(P), \dots, \nabla g_m(P)$ are linearly independent, then $\nabla f(P)$ is a linear combination of $\nabla g_1(P), \nabla g_2(P), \dots, \nabla g_m(P)$. \end{theorem} 
In the case of one constraint, $g(x_1, x_2, \dots, x_n) = k$, then $\nabla f = \lambda \nabla g$. 
\begin{example} Let $f(x, y, z) = xyz$ in a solid region bounded by $2x^2 + 3y^2 + 6z^2 = 18$ in the first quadrant ($x \geq 0, y \geq 0, z \geq 0$). \\~\\ On the interior, extremas occur at critical points. $$\nabla f = (yz, xz, xy) $$ This is zero once if 2 of $x, y, z$ are zero. Thus $f = 0$. Therefore no extremas on inside. On the boundary, look for max on the ellipsoid $$\nabla g = (4x, 6y, 12z)$$ Thus we have $$\begin{cases} \nabla f &= \lambda \nabla g \\ yz &= 4\lambda x \\ xz &= 6\lambda y \\ xy &= 12\lambda z \\ 2x^2 + 3y^2 + 6z^2 &= 18 \end{cases} $$ By the first equation, $\lambda = \frac{yz}{4x}$. Then $xz = 6(\frac{yz}{4x})y$ or $2x^2z = 3y^2z$ which simplifies to $2x^2 = 3y^2$. \end{example}
\begin{theorem} Lagrange Multiplier (one case): Let $g(x_1, x_2, \dots, x_n) = c$ and $f(x_1, x_2, \dots, x_n)$. The critical points of $f$ when restricted to the hypersurface defined by $g$ occurs when $\nabla f = \lambda \nabla g$. \end{theorem}
\begin{proof} Assume that $\nabla g(P) \neq 0$ at the critical point $P$. If some partial derivative, say $\frac{\partial g}{\partial x_n}\Big|_P \neq 0$, we can can solve for $x_n$ as a differentiable function of $x_1, x_2, \dots, x_{n - 1}$ in the neighborhood of $P$. (Let $x_n = h(x_1, x_2, \dots, x_{n - 1})$, then $g(x_1, x_2, \dots, x_n) = g(x_1, x_2, \dots, x_{n - 1}, h(x_1, x_2, \dots, x_{n - 1})) = c$). Thus $$\frac{\partial g}{\partial x_i} + \frac{\partial g}{\partial x_n}\frac{\partial x_n}{\partial x_i} = 0$$ at point $P$. Furthermore, $$\nabla g(P) = (-\frac{\partial g}{\partial x_n}\frac{\partial x_n}{\partial x_1}, \dots, -\frac{\partial g}{\partial x_n}\frac{\partial x_n}{\partial x_{n - 1}}, \frac{\partial g}{\partial x_n}) = -\frac{\partial g}{\partial x_n}(\frac{\partial x_n}{\partial x_1}, \dots, \frac{\partial x_n}{\partial x_{n - 1}}, -1 ) $$ When we look at composition $f(x_1, x_2, \dots, \underbrace{x_n}_{\text{as a function of } x_1, x_2, \dots, x_{n - 1}})$, we get a critical point. Hence the derivatives vanishes: $\frac{\partial f}{\partial x_i} + \frac{\partial f}{\partial x_n}\frac{\partial x_n}{\partial x_i} = 0$. Thus we find $\nabla f(P) = -\frac{\partial f}{\partial x_n}(\frac{\partial x_n}{\partial x_1}, \dots, \frac{\partial x_n}{\partial x_{n - 1}}, -1)$ at $P$. Since $\frac{\partial g}{\partial x_n}\Big|_P \neq 0$, we can write $\nabla f(P) = \lambda \nabla g(P)$ where $\lambda = \frac{\frac{\partial f}{\partial x_n}\Big|_P}{\frac{\partial g}{\partial x_n}\Big|P}$ \end{proof} 
\begin{definition} Lagrangian: $L(\vec{x}, \vec{\lambda}) = f(\vec{x}) - \sum_{j = 1}^m \lambda_j g_j(\vec{x})$. Set all partials with respect to $x_1, \dots, x_n$ and $\lambda_1, \dots, \lambda_n$ to 0. \end{definition}
\begin{example} Let $f = x^2 - 3x + y^2 - xy$ and let $D$ be a triangular region from (0, 4) to (4, 0) and $x + y = 4$. \\ Extreme Value Theorem: Continuous functions on a closed and bounded domain in $\mathbb{R}^n$ take on absolute maximum and absolute minimum. Closed region contains its boundary and bounded is contained in a ``large ball.''. $$\begin{aligned} f_x &= 2x - 3 - y = 0 \\ f_y &= 2y - x = 0 \end{aligned} $$ $P_0(2, 1)$is one critical point and is inside the region. $f(P_0) = -3$. \\ Boundary 1: $y = 0$ thus $f(x, 0) = x^2 - 3x$ in the region $0 \leq x \leq 4$. Critical Point: $P_1 = (\frac{3}{2}, 0)$. $f(P_1) = -\frac{9}{4}$; $P_2 = (0, 0)$. $f(P_2) = 0$; $P_3 = (4, 0)$. $f(P_3) = 4$. \\ 
Boundary 2: $x = 0$ thus $f(0, y) = y^2$ in the region $0 \leq y \leq 4$. Critical Point: $P_4 = (0, 4)$. $f(P_4) = 16$. \\ Boundary 3: $x + y = 4 \to y = x - 4$. Then $f(x, x - 4) = x^2 - 3x + (4 - x)^2 - 4x + x^2 = 2x^2 - 7x + (4 - x)^2$. $\frac{df}{dx} = 4x - 7 - 2(4 - x) = 0$. Therefore $x = \frac{5}{2}$. Critical Point: $P_5 = (\frac{5}{2}, \frac{3}{2})$. $f(P_5) = -\frac{11}{4}$. \\~\\ The maximum is $f(0,4) = 16$ and the minimum is $f(2, -1) = -3$. \end{example} 
\begin{theorem} Implicit Function Theorem (case of 1 equation): Let $f(x_1, x_2, \dots, x_n, z) = c$. Given sufficient differentiability ($C^1$ in the neighborhood of a point $P$), we want to use this equation to solve locally for $z$ as a $C^1$ function of $x_1, x_2, \dots x_n$. To do so, we will use $\frac{\partial f}{\partial z}\Big|P \neq 0$. Then $$\frac{\partial z}{\partial x_i} = -\frac{\frac{\partial f}{\partial x_i}}{\frac{\partial f}{\partial z}}$$ at point $P$. Indeed, if we know that $z$ is differentiable as a function of $x_1, x_2, \dots, x_n$, then $$\frac{\partial f}{\partial x_i} + \frac{\partial f}{\partial z}\frac{\partial z}{\partial x_i} = 0$$ at a point $P$ (Note, $1 \leq i \leq n$.) \end{theorem}
\begin{example} Let $f(x, y,) = x^2 + 5xy + 5y^3 = 19$ and P(x, y) = (2, 1). \\ A tangent line is $\nabla f$ perpendicular to the level set at P. $$\nabla f(x, y) = (2x + 5y, 5x + 15y^2) \to \nabla f(2, 1) = (9, 25) $$ The tangent line is $9(x - 2) + 25(y - 1) = 0$. By assuming that $\frac{\partial f}{\partial y}\Big|_P \neq 0$, we can use linear approximation to solve (approximate) for $z$ as a function of the other variables. $$y \sim 1 - \frac{9}{25}(x - 2)$$ where $$\frac{dy}{dx} = -\frac{\frac{\partial f}{\partial x}}{\frac{\partial f}{\partial y}} $$ \end{example}
\begin{example} Find the extremas of $f(x, y) = 1 + xy + 2x + y$ in the triangular region bounded by (-2, 5), (2, 1) and (-2, 1). \\ Extreme Value Theorem guarantees the existence of absolute max-min. Critical points are relative min-max on the interior. $$\begin{aligned} \frac{\partial f}{\partial x} &= y - 2 \\ \frac{\partial f}{\partial y} &= x + 1 \\ P(-1, 2) &\text{is one of the critical points.} \end{aligned} $$
Boundary 1: $y = 1 \to f(x, 1) = 2 - x$ in the region $-2 \leq x \leq 2$. Therefore critical points are (-2, 1) and (2, 1) \\ Warning: The function $f$ restricted to the boundary might have additional critical points. Thus check the end points and critical points. \\ Boundary: $x = -2 \to f(-2, y) = 5 - y$ in the region $-2 \leq y \leq 5$. There are no critical points here. \\ Boundary: Parameterize the hypotenuse: $(2, 1) + (-4, 4)t \to x = -2 - 4t$ in the region $0 \leq t \leq 1$. This means $y = 1 + 4t$ or $y - 1 = -1(x - 2)$ and so $y = -x + 3$. Hence $f(x, -x + 3) = 1 + x(3 - x) - 2x + 3 - x = -x^2 + 4$ in the region $-2 \leq x \leq 2$. A critical point here is (0, 3). \\~\\ f(0, 3) = 4, f(-2, 1) = 4, f(2, 1) = 0, f(-2, 5) = 0. The first two points are relative maximums and the latter two are relative minimums. \end{example} 
\begin{example} Let $f(x, y, z) = xy + z + 3xz^5 = 4$. Near the local solution of P(1, 0, 1), find $z = g(x, y)$ and find $\frac{\partial g}{\partial x}$ and $\frac{\partial g}{\partial y}$ at (1, 0). \\ $$\begin{aligned} \frac{\partial f}{\partial x} &= y + 3z^5 \to \frac{\partial f}{\partial x}\Big|_P = 3 \\ \frac{\partial f}{\partial y} &= x \to \frac{\partial f}{\partial y}\Big|_P \\ \frac{\partial f}{\partial z} &= 1 + 15xz^4 \to \frac{\partial f}{\partial z}\Big|_P = 16 \end{aligned} $$ Background: Linear approximation of $f(x, y, z)$ near $P$ is $4 + 3(x - 1) + y + 16(z - 1)$. \\ Tangent plane: $3(x - 1) + y + 16(z - 1) = 0$. Near $P$, $z$ can be approximated by $z = 1 - \frac{3}{16}(x - 1) - \frac{1}{16}y$. \\ Summary: To solve for $z$ locally at $P$, check $\frac{\partial f}{\partial z}\Big|_P \neq 0$. Now treat $z$ as a function of $x, y$. $$\frac{\partial z}{\partial x} = -\frac{\frac{\partial f}{\partial x}}{\frac{\partial f}{\partial z}} \text{ at } P $$ Thus in this example, $\frac{\partial z}{\partial x} = -\frac{3}{16}$. $$\frac{\partial z}{\partial y} = -\frac{\frac{\partial f}{\partial y}}{\frac{\partial f}{\partial z}} \text{ at } P $$ Thus in this example, $\frac{\partial z}{\partial y} = -\frac{1}{16}$. \end{example} 
\begin{theorem} General Implicit Function Theorem involving Several Equations: Assume all functions are $C^1$ in the neighborhood of $P$. We will have $m$ equations. If these equations are ``sufficiently independent,'' then we should be able to solve for $m$ variables, $z_1, z_2, \dots, z_m$, in terms of all the other variables $x_1, x_2, \dots, x_n$ locally near $P$: $\vec{z} = (z_1, z_2, \dots, z_n)$ near $\vec{b}$, $\vec{x} = (x_1, x_2, \dots, x_n)$ near $\vec{a}$ where $P = (\vec{a}, \vec{b})$. Given $m$ equations, $$ \begin{aligned} f_1(\vec{x}, \vec{z}) &= c_1 \\ f_2(\vec{x}, \vec{z}) &= c_2 \\ &\vdots \\ f_m(\vec{x}, \vec{z}) &= c_m \end{aligned} $$ Assume $f: \bigcup_a \times \bigcup_b \subseteq \mathbb{R}^{n + m} \to \mathbb{R}$. \end{theorem} 
\begin{example} Let $f_1(x, y, u, v) = x^2 + xu + y^2 + v^2 = 4$ and $f_2(x, y, u, v) = xz + yu = 2$. Let $P = (1, 1, 1, 1)$. We would like to solve for $u$ and $v$ as functions of $x$ and $y$ in the neighborhood of $P$ ($\vec{x} = (x, y)$, $\vec{z} = (u, v)$). \\ Notation: $\mathds{F} = (f_1, \dots, f_m): \bigcup_a \times \bigcup_b \subseteq \mathbb{R}^{n + m} \to \mathbb{R}^m$. $$\mathds{D}_{\vec{z}}\mathds{F} = \begin{pmatrix} \frac{\partial \mathds{F}_i}{\partial z_j} \end{pmatrix} (\text{of size } m \times m) $$ 
Standard Notation: $\frac{\partial (f_1, f_2, \dots, f_m)}{\partial (z_1, z_1, \dots, z_m)} = \det (\frac{\partial f_i}{\partial z_j}) $. \\ We assume that $\det \neq 0$ at $P$. This says that the gradient vectors $\nabla f_1, \nabla f_2, \dots, \nabla f_m$ are linearly independent at $P$. \\ Let's assume that we can solve for $z_1, z_2, \dots, z_m$ as differentiable functions of $x_1, x_2, \dots, x_n$ using $\vec{z} = g(\vec{x})$. Thus $\mathds{F}(\vec{x}, \vec{z}) = c$ and $\mathds{F}(\vec{x}, g(\vec{x})) = c$. Then $\mathds{D}\mathds{F} = 0$ or $$\underbrace{\mathds{D}_{\vec{x}}\mathds{F}}_{m \times n} + \underbrace{\mathds{D}_{\vec{z}}\mathds{F}}_{n \times m} \cdot \underbrace{\mathds{D}_{\vec{x}}\vec{z}}_{m \times n} = 0$$ 
If $\frac{\partial (f_1, f_2, \dots, f_m)}{\partial (z_1, z_2, \dots, z_m)}\Big|_P \neq 0$, we can solve for $\vec{z}$ in terms of $\vec{x}$ by linear approximation and $$\mathds{D}_{\vec{x}}\vec{z} = -(\mathds{D}_{\vec{z}}\mathds{F})^{-1} \cdot \mathds{D}_{\vec{x}}\mathds{F} \text{ at } P $$ 
In this example, we want to solve for $u$ and $v$. So we take the derivative matrix: $$\begin{pmatrix} \frac{\partial f_1}{\partial u} & \frac{\partial f_1}{\partial v} \\ \frac{\partial f_2}{\partial u} & \frac{\partial f_2}{\partial v} \end{pmatrix} = \begin{pmatrix} x & 2v \\ y & x \end{pmatrix} = \underbrace{\begin{pmatrix} 1 & 2 \\ 1 & 1 \end{pmatrix}}_{\det = -1 \neq 0} \text{ at } P $$ To find the derivative of $u$ and $v$ with respect to $x$ and $y$ $$\mathds{D}_{(x, y)}(f_1, f_2) = \begin{pmatrix} \frac{\partial f_1}{\partial x} & \frac{\partial f_1}{\partial y} \\ \frac{\partial f_2}{\partial x} & \frac{\partial f_2}{\partial y} \end{pmatrix} = \begin{pmatrix} 2x + u & 2y \\ u & v \end{pmatrix} = \begin{pmatrix} 3 & 2 \\ 1 & 1 \end{pmatrix} \text{ at } P $$ 
Therefore $$\mathds{D}_{(x, y)}(u, v) = -\begin{pmatrix} 1 & 2 \\ 1 & 1 \end{pmatrix}^{-1}\begin{pmatrix} 3 & 2 \\ 1 & 1 \end{pmatrix} = \begin{pmatrix} 1 & -2 \\ -1 & 1 \end{pmatrix}\begin{pmatrix} 3 & 2 \\ 1 & 1 \end{pmatrix} = \begin{pmatrix} 1 & 0 \\ -2 & -1 \end{pmatrix} $$ 
Thus $$\begin{pmatrix} u & v \end{pmatrix} = \begin{pmatrix} 1 \\ 1 \end{pmatrix} + \begin{pmatrix} 1 & 0 \\ -2 & -1 \end{pmatrix}\begin{pmatrix} x - 1 \\ y - 1 \end{pmatrix} $$ \end{example} 

Recall discussion of curves on $\mathbb{R}^n$. 
$$c(t) = (f_1(t), f_2(t), \dots, f_n(t)) \text{ where } t \in \text{ Interval } \subseteq \mathbb{R}^n$$ 
Assume differentiability. \\ 
Length of curve = $\int_{t_0}^{t_1} || c'(t) || \, dt $ \\
Limit exists for regular curves, more generally, if a curve has ``bounded variations.'' \\
Notation: $s$ represents arc length, differential: if $c = (x(t), y(t), z(t))$, then $d\vec{s} = (ds, dy, dz)$. 
\begin{definition} Dot Product Rule: Let $\vec{f}(t) = (f_1, f_2, \dots, f_n)$, $\vec{g}(t) = (g_1, g_2, \dots, g_n)$. Then $$F(t) = \vec{f} \cdot \vec{g} = f_1g_1 + f_2g_2 + \dots + f_ng_n$$ 
$$ F'(t) = \vec{f}' \cdot \vec{g} + \vec{f} \cdot \vec{g}' $$ \end{definition} 
\begin{definition} Vector Fields: Let $U \subseteq \mathbb{R}^n$. Then $F: U \to \mathbb{R}^n$ maps each point on $\mathbb{R}^n$ to a vector at that point \end{definition} 
\begin{definition} Scalar Fields: Let $U \to \mathbb{R}$ give rise to a gradient vector field \end{definition} 
If $\mathcal{F} = -\nabla f$, then $f$ is potential function for $\mathcal{F}$. \\ 
We showed that if $\vec{r} = (x, y, z)$, $\mathcal{F}(\vec{r}) = -\frac{1}{||\vec{r}||}\vec{r}$ whose magnitude is $\frac{1}{||\vec{r}||^2}$, then $f(\vec{r}) = \frac{1}{||\vec{r}||}$. 
\begin{definition} Total Energy: $$\frac{1}{2}m||\vec{r}'(t)||^2 + f(\vec{r})$$ Assume $\nabla f = -\mathcal{F}$. \end{definition}
Conservative Vector Field (gradient vector field): \\
Particle travels on path $\vec{r}(t)$. 
\begin{definition} Newton's Law: $$F(\vec{r}(t)) = m \cdot \vec{r}'(t)$$ \end{definition} 
\begin{definition} Total Energy: $$E = \frac{1}{2}m||\vec{r}'(t)||^2 + f(\vec{r}(t))$$ \end{definition} 
Check that energy is limited as a function of time $\frac{dE}{dt} = 0$. \\
Kinetic Energy Part: $\frac{1}{2}m\vec{r}(t) \cdot \vec{r}'(t)$ \\ Derivative = $\frac{1}{2}m \cdot 2\vec{r}'(t) \cdot \vec{r}''(t)$ \\ 
Potential Energy Part: $\nabla f(\vec{r}(t)) \cdot \vec{r}'(t) = -m\vec{r}''(t) \cdot \vec{r}'(t)$ \\ 
The sum of both derivatives equals zero. \\ 
Potential Vector Field: $F(x, y) = (-y, x)$. If these vectors represent velocity, the fluid is rotating around the origin. 
\begin{definition} Flow Lines: If the path of the particle is $\vec{r}(t)$, $\vec{r}'(t) = f(\vec{r}(t))$\end{definition} 
\begin{definition} Operator: $\nabla = (\frac{\partial}{\partial x}, \frac{\partial}{\partial y}, \frac{\partial}{\partial z})$ \end{definition} 
Let $f$ be a scalar field.
\begin{definition} Gradient Vector Field of $f$: $$\nabla f = (\frac{\partial f}{\partial x}, \frac{\partial f}{\partial y}, \frac{\partial f}{\partial z})$$ \end{definition} 
\begin{definition} Divergence: $$\nabla \cdot f = \frac{\partial f_1}{\partial x} + \frac{\partial f_2}{\partial y} + \frac{\partial f_3}{\partial z} $$ This is a dot product on a vector field $f$.  \end{definition} 
\begin{definition} Curl: $$\nabla \times f = \begin{pmatrix} \hat{i} & \hat{j} & \hat{k} \\ \frac{\partial}{\partial x} & \frac{\partial}{\partial y} & \frac{\partial}{\partial z} \\ F_1 & F_2 & F_3 \end{pmatrix} $$ 
This is a cross product with a vector field $F$. \end{definition}
Review: Implicit Function Theorem: Let $F(\overbrace{x_1, \dots, x_n}^{\vec{x}}, \overbrace{z_1, \dots, z_m}^{\vec{z}}) = (f_1(\vec{x}, \vec{z}), \dots, f_m(\vec{x}, \vec{z}))$ where $F: U \subseteq \mathbb{R}^{n + m} \to \mathbb{R}^m$. Use the $m^{\text{th}}$ equation created by setting $F(\vec{x}, \vec{z}) = \vec{c}$ to solve for $m$ variable in vector $\vec{z}$. Let $P(\vec{a}, \vec{b})$ in $\mathbb{R}^{n + m}$. There are neighborhoods $U_a$ of $\vec{a}$ in $\mathbb{R}^n$ and $U_b$ of $\vec{b}$ in $\mathbb{R}^m$ such that we can find $\vec{z} = g(\vec{x})$ where $g: U_a \to U_b$, provided that $F$ is $C^1$ on $U$ and $\frac{\partial(f_1, \dots, f_m)}{\partial(z_1, \dots, z_m)}(P) \neq 0$. \\
Notation: $$\mathds{D}_{\vec{z}}F = \Big(\frac{\partial f_i}{\partial z_j}\Big) \text{ where } 1 \leq i, j \leq m \text{ } m \times m \text{ matrix} $$ 
$$\frac{\partial f_i}{\partial z_j} = \det(\mathds{D}_{\vec{z}}F)$$ 
$$\mathds{D}_{\vec{x}}F = \Big(\frac{\partial f_i}{\partial x_j}\Big) \text{ where } 1 \leq i \leq m, 1 \leq j \leq n \text{ } m \times n \text{ matrix} $$ 
$$\mathds{D}_g = \mathds{D}_{\vec{x}}\vec{z} = \Big(\frac{\partial z_i}{\partial x_j}\Big) \text{ where } 1 \leq i \leq m, 1 \leq j \leq n \text{ } m \times n \text{ matrix} $$ 
$\mathds{D}_g$ treats $\vec{z}$ as a differentiable function of $\vec{x}$. 
$$\mathds{D}_{\vec{x}}\vec{z} = -(\mathds{D}_{\vec{z}}F)^{-1}\cdot(\mathds{D}_{\vec{x}}F) $$ 
To derive the last equation, assume that we can get $\vec{z}$ as a function of $\vec{x}$ locally. Therefore if $F(\vec{x}, \vec{z}) = 0$, $\mathds{D}_{\vec{x}}F + \mathds{D}_{\vec{z}}F \cdot \mathds{D}_{\vec{x}}\vec{z} = 0$. Solve for $\mathds{D}_{\vec{x}}\vec{z}$. Assume $\mathds{D}_{\vec{z}}F$ is invertible.
\begin{example} Solve the following equation for $z$ as a function of $x$ and $y$: $x^3z^2 - z^3yx = 0$. \\
Set up $F(x, y, z) = x^3z^2 - z^3yx$, which is $m \times 1$. Solve for $z$. Can we do this near (1, 1, 1) and (0, 0, 0)? \\ 
Condition: $\frac{\partial F}{\partial z}(P) \neq 0$. $$\frac{\partial F}{\partial z} = 2x^3z - 3z^2yx \to \frac{\partial F}{\partial z}\Big|_P = -1 \neq 0$$ 
We can see the solution $z = \frac{x^2}{y}$ near (1, 1, 1) since we know $x \neq 0$, $y \neq 0$ near the point. Think of $z$ as a function of $x, y$ near $P$. Find $\frac{\partial z}{\partial x}$ and $\frac{\partial z}{\partial y}$ at $P$. 
$$\frac{\partial F}{\partial x} = 3x^2z^2 - z^3y \to \frac{\partial F}{\partial x}\Big|_P = 2$$ 
$$\frac{\partial F}{\partial y} = -z^3x \to \frac{\partial F}{\partial y}\Big|_P = -1$$ 
$$\mathds{D}_{\vec{x}}\vec{z} = -(\mathds{D}_{\vec{z}}F)^{-1}\cdot(\mathds{D}_{\vec{x}}F) = -(-1) \cdot (\frac{\partial F}{\partial x}, \frac{\partial F}{\partial y}) = -(-1) \cdot (2, -1) = (2, -1)$$ 
Note that this would not work at (0, 0, 0). \\ 
By linear approximation $$ \begin{aligned} z &\approx 1 + (2, -1)\begin{pmatrix} x - 1 \\ y - 1 \end{pmatrix} \\ &\approx 1 + 2(x - 1) - (y - 1) \end{aligned} $$ \end{example} 
\begin{example} Let $z^2 + xy - a = 0$ and $z^2 + x^2 - y^2 - b = 0$. Solve for $x, y$ as a function of $z$. \\ Look at derivative of given relationships with respect to the variables you want to solve for. Expect a $2 \times 2$ matrix at $(x_0, y_0)$ in this example. $$\mathds{D}_{\{x, y\}}\{f_1, f_2\} = \begin{pmatrix} y_0 & x_0 \\ 2x_0 & -2y_0 \end{pmatrix} \to \frac{\partial (f_1, f_2)}{\partial (x, y)} = -2y_0^2 - 2x_0^2 $$ 
The only place where implicit solution fails is $(0, 0, z)$. What about $\frac{\partial x}{\partial z}$ and $\frac{\partial y}{\partial z}$? $$\mathds{D}_{\vec{z}}\{x, y\} = -(\mathds{D}_{\{x, y\}}\{f_1, f_2\})^{-1} \cdot \mathds{D}_{\vec{z}}\{f_1, f_2\} \text{ at } P $$ 
For the sake of this example, let $x = 1$, $y = 2$ and $z = 3$. (Hence $a = 11$ and $b = 6$.) 
$$\begin{pmatrix} \frac{\partial x}{\partial z} \\ \frac{\partial y}{\partial z} \end{pmatrix} = -\begin{pmatrix} 2 & 1 \\ 2 & -4 \end{pmatrix}^{-1} \begin{pmatrix} 6 \\ 6 \end{pmatrix} = \begin{pmatrix} -3 \\ 0 \end{pmatrix} $$ Linear Approximation: $$\begin{aligned} x &\approx 1 - 3(z - 3) \\ y &\approx 2 \end{aligned} $$ \end{example} 
\begin{example} Let $x^5v^2 + 2y^3u = 3$ and $3yu - xuv^3 = 2$. Solve for $u, v$ as functions of $x, y$ near (1, 1, 1, 1). 
$$\mathds{D}_{\{u, v\}} \{f_1, f_2\} = \begin{pmatrix} 2y^3 & 2x^5v \\ 3y - xv^3 & -3xuv^2 \end{pmatrix} = \begin{pmatrix} 2 & 2 \\ 2 & -3 \end{pmatrix} $$ The determinant of this matrix is not 0. $$\mathds{D}_{\{x, y\}} \{f_1, f_2\} = \begin{pmatrix} 5x^4v^2 & 6y^2u \\ -uv^3 & 3u \end{pmatrix} = \begin{pmatrix} 5 & 6 \\ -1 & 3 \end{pmatrix} \text{ at } P $$ 
$$\mathds{D}_{\{x, y\}} \{u, v \} = \begin{pmatrix} \frac{\partial u}{\partial x} & \frac{\partial u}{\partial y} \\ \frac{\partial v}{\partial x} & \frac{\partial v}{\partial y} \end{pmatrix} = \frac{1}{10}\begin{pmatrix} 2 & 2 \\ 2 & -3 \end{pmatrix}^{-1}\begin{pmatrix} 5 & 6 \\ -1 & 3 \end{pmatrix} = \begin{pmatrix} \frac{4}{5} & \frac{9}{5} \\ \frac{13}{10} & \frac{3}{10} \end{pmatrix} $$ 
Linear Approximation: $$\begin{aligned} u &\approx 1 - \frac{4}{5}(x - 1) - \frac{9}{5}(y - 1) \\ v &\approx 1 + \frac{13}{10}(x - 1) + \frac{3}{10}(y - 1) \end{aligned} $$ \end{example}
\begin{example} Prove the following: $$\Big(\frac{\partial y}{\partial x}\Big)\Big(\frac{\partial z}{\partial y}\Big)\Big(\frac{\partial x}{\partial z}\Big) = -1$$ 
Given one solution, $f(x, y, z)$ = constant. \\ $$\frac{\partial y}{\partial x} = -\frac{F_x}{F_y} \text{ } \frac{\partial z}{\partial y} = -\frac{F_y}{F_z} \text{ } \frac{\partial x}{\partial z} = -\frac{F_z}{F_x} $$ 
Therefore $$-\frac{F_x}{F_y} \cdot -\frac{F_y}{F_z} \cdot -\frac{F_z}{F_x} = -1$$ \end{example} 
\begin{theorem} Special Case of the Implicit Function Theorem: Inverse Implicit Function Theorem \\ 
Let $z_1 = f_1(\vec{x})$ to $z_m = f_m(\vec{x})$ where $\vec{x} = (x_1, \dots, x_m)$. Let $F: U \subseteq \mathbb{R}^m \to \mathbb{R}^m$ and $F(\vec{a}) = \vec{b}$. We want to use these equations to solve for the $x$'s in terms of $\vec{z}$. Let $\tilde{f}_1(\vec{x}) = f_1(\vec{x}) - z_1$ to $\tilde{f}_m(\vec{x}) = f_m(\vec{x}) - z_m$. Let $\mathcal{G} = (\tilde{f}_1, \dots, \tilde{f}_m)$. Assuming $f_1, \dots, f_m$ are $C^1$, we now have $G(\vec{x}, \vec{z}) = 0$ in equations that we should be able to solve for $\vec{x}$ in terms of $\vec{z}$. Check invertibility of $\mathds{D}_{\text{variables to \\ solve for}} \{\text{given equations}\}$. $$\mathds{D}_{\vec{x}}\{\tilde{f}_1, \dots, \tilde{f}_m\} = \mathds{D}_{\vec{x}}\{f_1, \dots, f_m\} = \mathds{D}_{\vec{x}} \{\vec{z}\} $$ We want $\det \frac{\partial(f_1, \dots, f_m)}{\partial (x_1, \dots, x_m)} \neq 0$. If so, note that $$\mathds{D}_{\text{other variables}}\{\text{given equations}\} = \begin{pmatrix} -1 & 0 & 0 \\ 0 & -1 & 0 \\ 0 & 0 & -1 \end{pmatrix} = -I $$ 
Therefore $$\mathds{D}_{\vec{z}}\{\vec{x}\} = -(\mathds{D}_{\vec{x}}\{\vec{z}\})^{-1}(-I) = (\mathds{D}_{\vec{x}}\{\vec{z}\}) \text{ at } P $$ \end{theorem} 
\begin{example} Let $F(x, y) = (2x, 3y)$. $$\div F = 2 + 3 = 5$$ 
Can we find flow lines here? $$\vec{c}(t) = (x(t), y(t))$$ We want $$\begin{pmatrix} x'(t) \\ y'(t) \end{pmatrix} = \begin{pmatrix} 2x(t) \\ 3y(t) \end{pmatrix} $$ Therefore $x' = 2x$ and $y' = 3y$. By solving for $x$ and $y$, we get $x = c_1e^{2t}$ and $y = c_2e^{3t}$. \\ $\curl F = 0$. Is $F$ a gradient vector field? Find a vector field $f$ such that $\nabla f = F$. $$\begin{aligned} f_x &= 2x \\ f_y &= 3y  \\ f &= x^2 + g(y) \\ f &= \frac{3}{2}y^2 + h(x) \\ f(x, y) &= x^2 + \frac{3}{2}y^2 \end{aligned} $$ \end{example} 
\begin{theorem} Let $F = (P, Q, R)$ be a $C^2$ vector field. If $F = \nabla f$ is a gradient vector field, then $\curl(F) = 0$. \end{theorem} 
\begin{proof} By assumption, $P = f_x$, $Q = f_y$ and $R = f_z$. 
$$\curl F = (R_y - Q_z, P_z - R_x, P_y - Q_x) = (f_{zy} - f_{yz}, f_{xz} - f_{zx}, f_{xy} - f_{yx}) $$ \end{proof} \begin{example} Let $F = (3x^2 + 2xy, 4y^3 + x^2)$. Find $f$ such that $f = \nabla F$. $$\begin{aligned} f_x &= 3x^2 + 2xy \\ f_y &= 4y^3 + x^2 \end{aligned} $$ First check that $Q_x = P_y$. $$2x = 2x$$ 
$$\begin{aligned} f &= x^3 + x^2y + g(y) \\ &\text{differentiate with respect to } y \\ x^2 + g'(y) &= 4y^3 + x^2 \\ g(y) &= y^4 + c \\ f(x, y) = x^3 + x^2y + y^4 + c \end{aligned} $$ \end{example} 
\begin{example} Let $F(x, y) = (-y, x)$. $$\curl F = (0, 0, 2)$$ 
This cannot be a gradient vector field. No potential function. \\ How do we find integral curves?
$$ \begin{aligned} \vec{c}(t) &= (x(t), y(t)) \\ \vec{c}' &= F(x'(t), y'(t)) = (-y, x) \\ x' &= y \\ y' &= x \end{aligned} $$ Trick: $h = x^2 + y^2$ as a function of $t$. $$h'(t) = 2x\frac{dx}{dt} + 2y\frac{dy}{dt} = 2x(-y) + 2y(x) = 0 $$ Integral curves are given explicitly by $x^2 + y^2 = $ constant. $$\div F = 0$$ \end{example} 
Formulae for Gradient, Divergence, Curl \begin{enumerate} 
\item $\nabla (f + g) = \nabla f + \nabla g$
\item $\nabla (cf) = c\nabla f$, for a constant $c$ 
\item $\nabla (fg) = f\nabla g + g\nabla f$ 
\item $\nabla(\frac{f}{g}) = \frac{g\nabla f - f\nabla g}{g^2}$, at points $\vec{x}$ where $g(\vec{x}) \neq 0$
\item $\div (F + G) = \div F + \div G $ 
\item $\curl (F + G) = \curl F + \curl G $ 
\item $\div (fF) = f\div F + F \cdot \nabla f $ 
\item $\div (F \times F) = G \cdot \curl F - F \cdot \curl G$
\item $\div \curl F = 0$
\item $\curl (fF) = f\curl F + \nabla f \times F $ 
\item $\curl \nabla f = 0$
\item $\nabla^2 (fg) = f\nabla^2g + g\nabla^2f + 2(\nabla f \cdot \nabla g) $
\item $\div(\nabla f \times \nabla g) = 0$
\item $\div(f\nabla g - g\nabla f) = f\nabla^2g - g\nabla^2f $  \end{enumerate} 
\begin{theorem} Let an integral be defined by Riemann sums. Choose partitions and sample points. Tehe limit must exist independent of choice. Then continuous functions on closed and bounded sets can be integrate. Some discontinuous functions also can be integrated. \end{theorem} 
\begin{example} Change the order of integration for $\int_0^r \int_x^r \sqrt{r^2 - y^2} \, dydx $ where $r$ is constant. \\ Inside: $y = x$ to $y = r$. Outside: $x = 0$ to $x = r$. $y$ moves first ($x$ held constant). Instead, let $x$ move first. Starts from $x = 0$ to $x = y$. Then let $y$ move from $y = 0$ to $y = r$. 
$$\int_0^r \int_0^y \sqrt{r^2 - y^2} \, dxdy = \int_0^r \sqrt{r^2 - y^2}x\Big|_0^t \, dy = \int_0^r y\sqrt{r^2 - y^2} \, dy $$ \end{example} 
\begin{example} Change the order of integration for $\int_0^4 \int_0^x f(x, y) \, dydx + \int_4^{\sqrt{32}} \int_0^{\sqrt{32 - x^2}} f(x, y) \, dydx$. \\
 First $y$ goes from $y = 0$ to $y = x$, and then $x$ goes from $x = 0$ to $x = 4$. On the other side, $y$ goes from $y = 0$ to $y = \sqrt{32 - x^2}$ (the circle), and then $x$ goes from $x = 0$ to $x = \sqrt{32}$. Now let $x$ go from $x = y$ to $x = \sqrt{32 - y^2}$ and $y$ from $y = 0$ to $y = 4$. $$\int_0^4 \int_y^{\sqrt{32 - y^2}} f(x, y) \, dxdy $$ \end{example} 
 \begin{example} Find the volume enclosed by the cylinder formed by $y = 5 - x^2$ and $y = x^2 - 3$ in $\mathbb{R}^3$ and lying in between planes $2x + 3y + z = 8$ and $x + y - z = 16$. \\ $\int \int (\text{height}) \, dA$ will represent the volume. $z$ will be controlled by the equations of the planes. $$\begin{aligned} z &= 8 - 2x - 3y \\ z &= x + y - 16 \end{aligned} $$ Which is the upper and lower? First look at the $xy$-region. Where do these two parabolas meet in $xy$-plane? $$5 - x^2 = x^2 + 3 \to x = \pm 2$$ 
 At (0, 0), which is in the region of intersection, the first plane is upper. Check that the planes do not intersect with region of interest. The planes met where $x + y - 16 = 8 - 2x - 3y$ or $3x + 4y = 24$. $$\iint (8 - 2x - 3y) - (x + y - 16) \, dA = \iint (24 -3x - 4y) \, dA $$ Use $dA = dydx$ because letting $y$ move first gives consistent upper and a consistent lower boundary. $$\int_{-2}^2 \int_{x^2 + 3}^{5 - x^2} (24 - 3x - 4y) \, dydx $$ \end{example} 
 \begin{example} Let $u = x + xyz$, $v = y + xy$ and $w = z + 2x + 3z^2$ ($F: \mathbb{R}^3 \to \mathbb{R}^3$ or $(x,y,z) \to (u, v, w)$) near $F(0, 0, 0) = (0, 0, 0)$. Does the inverse of $F$ exist locally centered at these points? \\ Matrix for Derivatives of $u, v, w$ with respect to $x, y, z$: 
 $$\mathds{D}_{\{x, y, z\}}\{u, v, w\} = \begin{pmatrix} 1 + yz & xz & xy \\ y & 1 + x & 0 \\ 2 & - & 1 + 6z \end{pmatrix} = \begin{pmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 2 & 0 & 1 \end{pmatrix} \text{ at } P $$ The determinant of this matrix is 1 and therefore the matrix is invertible. Given all functions are $C^1$, invertibility of this matrix implies local inverse exists and is $C^1$. What is $\mathds{D}_{\{u, v, w\}} \{x, y, z\}(P)$? $(\text{previous matrix})^{-1}$. $$\begin{pmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ -2 & 0 & 1 \end{pmatrix} $$ $$\frac{\partial u}{\partial x}\Big|_P = 1 ~~ \frac{\partial v}{\partial y}\Big|_P = 1 ~~ \frac{\partial w}{\partial z}\Big|_P = 1 ~~ \frac{\partial u}{\partial z}\Big|_P = -2 $$ \end{example} 
 \begin{example} Let $x^2 - y^2 - u^3 - v^2 + 4 = 0$ and $2xy + y^2 - 2u^2 + 3v^4 + 8 = 0$. Solve for $u, v$ in terms of $x, y$ near $P(2, -1, 2, 1)$. 
 $$\mathds{D}_{\{u, v\}}\{f_1, f_2\} = \begin{pmatrix} -3u^2 & 2v \\ -4u & 12v^2 \end{pmatrix} \to \begin{pmatrix} -12 & 2 \\ -8 & 12 \end{pmatrix} \text{ at } P $$ 
 This matrix is invertible and so local solutions exists. 
  $$\mathds{D}_{\{x, y\}}\{f_1, f_2\} = \begin{pmatrix} 2x & -2y \\ 2y & 2x + 2y \end{pmatrix} \to \begin{pmatrix} 4 & 2 \\ -2 & 2 \end{pmatrix} \text{ at } P $$ 
 Let $ \begin{pmatrix} u \\ v \end{pmatrix}  = G\begin{pmatrix} x \\ y \end{pmatrix} $ be locally defined around the given point. What is the Jacobian derivative? $$\mathds{D}_{\{x, y\}}\{u, v \} = -\Big(\mathds{D}_{\{u, v\}}\{x, y\}\Big)^{-1} \cdot \mathds{D}_{\{x, y\}}\{f_1, f_2\}  = -\begin{pmatrix} -12 & 2 \\ -8 & 12 \end{pmatrix}^{-1}\begin{pmatrix} 4 & 2 \\ -2 & 2 \end{pmatrix} = \frac{1}{128}\begin{pmatrix} 52 & 20 \\ 56 & -8 \end{pmatrix} $$ \end{example} 
 \begin{example} Let $F(x, y, z) = (3x^2 - 2x^2 - y^2, 3y^2 - 2xy - z^2, 3z^2 - 2y^2 - x^2)$. Is there a gradient vector field? In other words, can you find a potential function $f$ such that $F = \nabla f$? \\ Necessary condition for existence of $F = \nabla f: \curl(F) = 0$. This is assuming $f$ is $C^2$ or equivalently, $F$ is $C^1$. $$\curl(F) = \begin{pmatrix} \hat{i} & \hat{j} & \hat{k} \\ \frac{\partial}{\partial x} & \frac{\partial}{\partial y} & \frac{\partial}{\partial z} \\ P & Q & R \end{pmatrix} = (R_y - Q_z, P_z - R_x, Q_x - P_y) = (0, 0, 0) $$ 
 Now try for $f$: $$\begin{aligned} f &= x^3 - x^2z - xy^2 + g(y, z) \\ f_y &= -2xy + \frac{\partial g}{\partial y} = -2xy + 3y^2 - z^2 \\ \frac{\partial g}{\partial y} &= 3y^2 - z^2 \\ g &= y^3 - yz^2 + h(z) \\ f &= x^3 - x^2z - xy^2 + y^3 - yz^2 + h(z) \\ f_z &= -x^2 - 2yz + h'(z) = 3z^2 - 2yz - x^2 \\ h'(z) &= 3z^2 \\ h(z) &= z^3 \\ f&= x^3 - x^2z - xy^2 + y^3 - yz^2 + z^3 \end{aligned} $$ \end{example} 
 \begin{example} Let $z = \sqrt{x^2 + y^2}$ be a cone and $z = x^2 + y^2$ be a paraboloid. Suppose $f(x, y, z)$ represents density. Find the mass of the region $R$. \\ Check which is top and bottom in $yz$ plane. $$ z = \sqrt{0^2 + y^2} = y \text{ if positive }, z = 0 + y^2 = y^2 $$ Since $y^2 > y$, $z = \sqrt{x^2 + y^2}$ is the top function and $z = x^2 + y^2$ is the bottom function. $$\iiint f(x, y, z) \, dV = \iint \int_{x^2 + y^2}^{\sqrt{x^2 + y^2}} f(x, y, z) \, dzdA $$ Next use projection to $xy$ plane. Where do the paraboloid and cone meet? $$\begin{aligned} x^2 + y^2 &= \sqrt{x^2 + y^2} \\ (x^2 + y^2)^2 &= x^2 + y^2 \\ x^2 + y^2 &= 1 \end{aligned} $$ This is a circle of radius 1 centered around the origin. Say we decide $dA = dxdy$. Then $x = \pm \sqrt{1 - y^2}$. $$\iint_{-\sqrt{1 - y^2}}^{\sqrt{1 - y^2}} \int_{x^2 + y^2}^{\sqrt{x^2 + y^2}} f(x, y, z) \, dzdxdy = \int_{-1}^1 \int_{-\sqrt{1 - y^2}}^{\sqrt{1 - y^2}} \int_{x^2 + y^2}^{\sqrt{x^2 + y^2}} f(x, y, z) \, dzdxdy $$ One could also hope to use polar coordinates for the region in the plane. Express $f(x, y, z)$ in terms of polar variables: $f(r\cos \theta, r\sin \theta, z)$ where $r, \theta, z$ are cylindrical coordinates. $$ \iiint f(r\cos \theta, r\sin \theta, z) \, dzrdrd\theta = \int_0^{2\pi} \int_0^1 \int_{r^2}^r f(r\cos \theta, r\sin \theta, z) \, dzrdrd\theta $$ \end{example} 
 
 \begin{example} Let $x^2 + y^2 + z^2 \leq 4$ be a ball and $2x^2 + z^2 = 1$ be a cylinder. Find the mass of the intersection. $$\iiint_{-\sqrt{4 - x^2 - z^2}}^{\sqrt{4 - x^2 - z^2}} f(x, y, z) \, dydA $$ 
 In the $xz$ plane, determined by the elliptic cylinder, $$ 2x^2 + z^2 = 1 \to x = \sqrt{\frac{1 - z^2}{2}} = \pm \frac{1}{\sqrt{2}} $$ $$\int_{-\frac{1}{\sqrt{2}}}^{\frac{1}{\sqrt{2}}} \int_{-\sqrt{1 - x^2}}^{\sqrt{1 - x^2}} \int_{-\sqrt{4 - x^2 - z^2}}^{\sqrt{4 - x^2 - z^2}} f(x, y, z) \, dydzdx $$ \end{example} 
 
 \begin{example} Let $x + y = 4$, $x + y - z = -1$ be bounded by $x = y = z = 0$. Find the mass of the region. $$\iiint_0^{x + y - 1} f(x, y, z) \, dzdA $$ In the $xy$ plane, $x + y = 4$ and $x + y = -1$ (plays no role in the first quadrant). Therefore $$\int_0^4 \int_0^{4 - y} \int_0^{x + y - 1} f(x, y, z) \, dzdxdy $$ \end{example} 
 
 \begin{example} Let $D$ be the region enclosed by the $y$-axis and $x = -4y^2 + 3$. Solve $\iint_D x^2y \, dxdy$. \\ Let $x$ move first from $x = 0$ to $x = -4y^2 + 3$. $$\iint_0^{-4y^2 + 3} x^2y \, dxdy $$ When $x = 0$, $-4y^2 + 3 = 0 \to y = \pm \frac{\sqrt{3}}{2}$. $$\int_{-\frac{\sqrt{3}}{2}}^{\frac{\sqrt{3}}{2}} \int_0^{-4y^2 + 3} x^2y \, dxdy $$ In the other way around, $$\int_0^3 \int_{-\frac{1}{2}\sqrt{3 - x}}^{\frac{1}{2}\sqrt{3 - x}} x^2y \, dydx $$ \end{example} 
 
 \begin{example} Change the order of variables: $\int_0^4 \int_{\frac{y}{2}}^2 e^{x^2} \, dxdy $. \\ First, $x$ moves from $x = \frac{y}{2}$ to $x = 2$. This is the line $y = 2x$ from $x = 0$ to $x = 2$. Then $y$ goes from $y = 0$ to $y = 4$. Now let $y$ move first, from $y = 0$ to $y = 2x$. Then $x$ will move from $x = 0$ to $x = 4$. $$\int_0^2 \int_0^{2x} e^{x^2} \, dydx = \int_0^2 ye^{x^2} \Big|_{y = 0}^{y = 2x} \, dx = \int_0^2 2xe^{x^2} \, dx = e^{x^2}\Big|_0^2 = e^4 - 1 $$ \end{example} 
 
 Transformations on a Plane: $T: \mathds{D}_{u, v}^* \to \mathds{D}_{x, y}$ or $T\begin{pmatrix} u \\ v \end{pmatrix} = \begin{pmatrix} x \\ y \end{pmatrix} $. \\
 Linear functions occur as multiplication by a $2 \times 2$ matrix. For example, $T\begin{pmatrix} 1 & 2 \\ 4 & 1 \end{pmatrix} $ means $x = u + 2v$ and $y = 4u + v$. \\ In general, linear transformations map lines to lines. In addition, area is stretched by $| \det(T) |$ under a linear transformation. The sign of the $\det T$ determines the orientation. \\~\\
 Polar: $[0, A] \times [0, 2\pi]$ creates a box in the $r,\theta$ plane. $T\begin{pmatrix} r \\ \theta \end{pmatrix} = \begin{pmatrix} r\cos \theta \\ r\sin \theta \end{pmatrix} $. If $\theta$ is a constant, we get a ray making angle $\theta$ with the $x$ axis, going out to $r = A$. Then $\theta$ moves to swing say around and cover disk of radius $A$ centered at the origin. \\~\\
 Let $x = uv$ and $y = u^2 + v^2$. In $\mathds{D}^*$, this is a line from (0, 0) to (1, 1) on the $uv$ plane. On the $u$ axis, $T\begin{pmatrix} u \\ 0 \end{pmatrix} = \begin{pmatrix} 0 \\ u^2 \end{pmatrix}$. On $u = 1$ from $v = 0$ to $v = 1$, $T\begin{pmatrix} 1 \\ v \end{pmatrix} = \begin{pmatrix} v \\ v^2 + 1 \end{pmatrix} $. This is a graph of $y = x^2 + 1$ from $x = 0$ to $x = 1$. On the line $u = v$, $T\begin{pmatrix} u \\ u \end{pmatrix} = \begin{pmatrix} u^2 \\ 2u^2 \end{pmatrix}$. This is a graph of $y = 2x$ from $x = 0$ to $x = 1$. The symmetry in $u, v$ suggests that the image of $1 \times 1$ square under $T$ covers region $\mathds{D}$ twice. We would like $T: \mathds{D}^* \to \mathds{D}$ to be surjective (onto). This means $T(\mathds{D}^*) \to D$. We also want $T$ to be injective (1-1). This means if $T\begin{pmatrix} u \\ v \end{pmatrix} = \begin{pmatrix} u' \\ v' \end{pmatrix}$, then $\begin{pmatrix} u \\ v \end{pmatrix} = \begin{pmatrix} u' \\ v' \end{pmatrix} $. If a transformation is both 1-1 and onto, there is a set-theoretic inverse function that is bijective. \\
 \begin{theorem} Suppose $F$ is a $C^1$ function and $F = \nabla f$ for some scalar field $f$. Then $\curl(F) = 0$ ($\nabla \times F = 0$). \end{theorem} 
 \begin{proof} Let $F = P\hat{i} + Q\hat{j} + R\hat{k}$. In general, $\nabla \times F$ is symbolically as $$\det \begin{pmatrix} \hat{i} & \hat{j} & \hat{k} \\ \frac{\partial}{\partial x} & \frac{\partial}{\partial y} & \frac{\partial}{\partial z} \\ P & Q & R \end{pmatrix} = (R_y - Q_z, P_z - R_z, Q_x - P_y)$$ We are given that $F = \nabla f$, or $P = f_x$, $Q = f_y$ and $R = f_z$. $$\nabla \times F = (f_{zy} - f_{yz}, f_{xz} - f_{zx}, f_{yx} - f_{xy})$$ Since $F$ is $C^1$, we know $f$ is $C^2$. Thus the mixed partials are equal and therefore cancel out. \end{proof} 
 \begin{example} Inverse Function Theorem: Let $F: \mathbb{R}^2 \to \mathbb{R}^2$ or $\begin{pmatrix} x \\ y \end{pmatrix} \to \begin{pmatrix} u \\ v \end{pmatrix} $. Let $u = x^2 - y^2$ and $v = xy$. Alternatively, $F\begin{pmatrix} x \\ y \end{pmatrix} = \begin{pmatrix} x^2 - y^2 \\ xy \end{pmatrix} $. Can we find a local inverse? \\ Solve for $x, y$ in terms of $u, v $. Find $G$ so that $F \cdot G = G \cdot F$. Consider $$ \frac{\partial (u, v)}{\partial (x, y)} = \det \begin{pmatrix} 2x & -2y \\ y & x \end{pmatrix} = 2(x^2 + y^2) $$ As long at $(x, y) \neq (0, 0)$, local inverses exist. \\ Furthermore, if ew think $\begin{pmatrix} x \\ y \end{pmatrix} = G\begin{pmatrix} u \\ v \end{pmatrix}$, then $$\mathds{D}_{\{u, v\}}\{x, y\} = \mathds{D}_{\{x, y\}}\{u, v\}^{-1} $$ at $P$. This exists because $\det(P) = 0$. More specifically, we could take $(x, y) = (3, 2)$ and $(u, v) = (5, 6)$. Find linear approximations to the inverse function $G$ $$\begin{aligned} \mathds{D}_{\{x, y\}}\{u, v\} &= \begin{pmatrix} 6 & -4 \\ 2 & 3 \end{pmatrix} &\text{ at } P \\ \mathds{D}_{\{u, v\}}\{x, y\} &= \begin{pmatrix} 6 & -4 \\ 2 & 3 \end{pmatrix}^{-1} = \frac{1}{26} \begin{pmatrix} 3 & 4 \\ -2 & 6 \end{pmatrix} \\ \begin{pmatrix} x \\ y \end{pmatrix} &\approx \begin{pmatrix} 5 \\ 2 \end{pmatrix} + \frac{1}{26}\begin{pmatrix} 3 & 4 \\ -2 & 6 \end{pmatrix}\begin{pmatrix} u - 5 \\ v - 6 \end{pmatrix} \end{aligned} $$ \end{example} 
 \begin{theorem} Let $F(\vec{x}, \vec{z})$ = constant where $F = (f_1, \dots, f_m)$. Let $P = (\vec{a}, \vec{b})$ where $\vec{x}$ is in a neighborhood of $\vec{a}$ and $\vec{y}$ is in the neighborhood of $\vec{b}$. If $F$ is $C^1$ and $\frac{\partial (f_1, \dots, f_m)}{\partial (z_1, \dots, z_m)} \neq 0$ at $P$, then we can find suitable neighborhoods $U_a$ and $U_b$ to express $\vec{z} = G(\vec{x})$ solving for $\vec{z}$ in terms of $\vec{x}$. Furthermore $G$ is $C^1$. Then we can find $\mathds{D}_{\vec{x}}\vec{z}$ $$\mathds{D}_{\vec{z}}F + \mathds{D}_{\vec{z}}F \cdot \mathds{D}_{\vec{x}}\vec{z} = 0 $$ At $P$, we know $\mathds{D}_{\vec{z}} F$ has nonzero determinant, so it is invertible. Thus we can solve for $$\mathds{D}_{\vec{x}}\vec{z} = -(\mathds{D}_{\vec{z}}F)^{-1} \cdot (\mathds{D}_{\vec{x}}F) $$ \end{theorem} 
 \begin{example} Solve $\iiint_W (1 - z^2) \, dV$ where $W$ is the pyramid with top vertex at (0, 0, 1) and base vertices at (0, 0, 0), (1, 0, 0), (0, 1, 0) and (1, 1, 0). \\ Say we do $dx$ first. The boundaries are coordinate planes (0, 0, 0) at bottom. Other two triangular bases of pyramid: $$\begin{aligned} Q - P &= (1, 0, -1) \\ R - P &= (1, 1, -1) \\ (Q - P) \times (R - P) &= (1, 0, 1) \\ 1(x - 0) + 0(y - 0) + 1(z - 1) &= 0 \\ x + z &= 1 \\ PRS: y + z &= 1 \\ \iiint_0^{1 - z} (1 - z^2) \, dxdA \\ \int_0^1 \int_0^{1 - z} \int_0^{1 - z} (1 - z^2) \, dxdydz & \end{aligned} $$ \end{example} 
 \begin{definition} If $F$ is a gradient vector field ($F = \nabla f$), for some scalar field $f$, then $f$ is called a potential function and $F$ is called a conservative vector field. Necessary criterion: $\nabla \times F = 0$. \end{definition} 
 One can show from equality of mixed partials that $\div(\curl F) = 0$. 
 \begin{example} Let $x^2 + y^2 = a^2$ and $x^2 + z^2 = a^2$ be two intersecting cylinders. Find the volume of the region common the intersecting cylinders. \\ Take the volume within both cylinders simultaneously and in first octant, then multiply by 8. $$\begin{aligned} 8\iiint_0^{\sqrt{a^2 - x^2}} \, dzdA &= 8\int_0^a \int_0^{\sqrt{a^2 - x^2}} \int_0^{\sqrt{a^2 - x^2}} \, dzdydx \\ &= 8\int_0^a \int_0^{\sqrt{a^2 - x^2}} \sqrt{a^2 - x^2} \, dydx \\ &= 8\int_0^a \sqrt{a^2 - x^2} \sqrt{a^2 - x^2} \, dx \\ &= 8\int_0^a (a^2 - x^2) \, dx \\ &= 8(a^2x - \frac{x^3}{3})\Big|_0^a \\ &= 8(a^3 - \frac{a^3}{3}) \\ &= 8 \cdot \frac{2}{3}a^3 \\ &= \frac{16}{3}a^3 \end{aligned} $$ \end{example} 
 \begin{example} Find the volume of the intersection of $x^2 + y^2 \leq 1$, $z \leq 0$ and $x^2 + y^2 + z^2 \leq 4$. \\ 
 Due to symmetry, the volume can be found by finding the volume in the first quadrant and then multiplying by 4. 
 $$ 4\iiint_0^{\sqrt{4 - x^2 - y^2}} \, dzdA = 4\int_0^1 \int_0^{\sqrt{1 - x^2}} \int_0^{\sqrt{4 - x^2 - y^2}} \, dzdydx $$ \end{example} 
 
 
 
 
 
 
 
 Let $f(t)$ and $g(t)$ be curves where $f(t) = (x_1(t), y_1(t), z_1(t))$ and $g(t) = (x_2(t), y_2(t), z_2(t))$. Let $P(t) = f(t) \cdot g(t)$. By the product rule, $$P'(t) = f'(t) \cdot g(t) + f(t) \cdot g'(t)$$ 
 If $N(t) = |f(t)|^2 = f(t) \cdot f(t)$, then $N'(t) = 2f(t) \cdot f'(t)$. Given that acceleration and velocity are perpendicular, or $f''(t) \perp f'(t)$, or $f'(t) \cdot f''(t) = 0$, show that speed, or $||f'(t)||$ is constant. \\ Let $h(t) = ||f'(t)||^2 = f'(t) \cdot f'(t)$. Show that the derivative of $h(t)$ is zero. But $h'(t) = 2f'(t) \cdot f''(t) = 0$. Therefore speed is constant. \\~\\ 
 We had discussed transformations in $\mathbb{R}^2$. Now let apply it to change of variables for multiple integrals. \\ Let $T$ be a transformation $\mathds{D}^*$ in $(u, v)$ to $\mathds{D}$ in $(x, y)$ on $\mathbb{R}^2$. $$\iint_{\mathds{D}} f(x, y) \, dydx = \iint_{\mathds{D}^*} (f \cdot T)(u, v) \Big| \frac{\partial (x, y)}{\partial (u, v)} \Big| \, dudv $$ $T$ should be bijective $\mathds{D}^* \to \mathds{D}$ and $C^1$. Here $f$ is continuous expect possibly on a parameterized curve where $f$ is bounded. Also similarly, $T$ may not be bijective on a parameterized curve in $\mathds{D}^*$. 
 \begin{example} Let $x = r\cos \theta$ and $y = r\sin \theta$. Let $T$ be a transformation $\mathds{D}^*$ in $(r, \theta)$ to $\mathds{D}$ in $(x, y)$. $$\frac{\partial (x, y)}{\partial (r, \theta)} = \det \begin{pmatrix} \cos \theta & -r\sin \theta \\ \sin \theta & r\cos \theta \end{pmatrix} = r $$ Therefore $$\iint f(x, y) \, dydx = \iint f(r\cos \theta, r\sin \theta) \, rdrd\theta $$ \end{example} 
 \begin{example} Let $\int_{-\infty}^{\infty} e^{-\frac{1}{2}x^2} \, dx$. Call this value $I$. $$\begin{aligned} I^2 &= (\int_{-\infty}^{\infty} e^{-\frac{1}{2}x^2} \, dx)(\int_{-\infty}^{\infty} e^{-\frac{1}{2} y^2} \, dy) \\ &= \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} e^{-\frac{1}{2}(x^2 + y^2)} \, dydx \\ &= \int_0^{2\pi} \int_0^{\infty} e^{-\frac{1}{2}r^2} \, rdrd\theta \\ &= \int_0^{2\pi} -e^{-\frac{1}{2}r^2} \Big|_0^{\infty} \, d\theta \\ &= \int_0^{2\pi} \, d\theta \\ &= 2\pi \\ I &= \sqrt{2\pi} \end{aligned} $$ \end{example} 
 \begin{example} Reparameterize $\iint_D \sqrt{x^2 - y^2} \, dydx$ where $D$ is an arc from the origin starting at (1,0) and going to (1,1). By the transformation $S$ of $\begin{pmatrix} x \\ y \end{pmatrix} \to \begin{pmatrix} u \\ v \end{pmatrix}$, $x + y = 2u$ and $x - y = 2v$. \\ Change of variables: $\mathds{D}^*$ in $uv$ plane. Linear transformation lines go to lines. Find the range of vertices and convert them. $$\begin{aligned} (1, 1) &\to S(2, 0) \\ (1, 0) &\to S(1, 1) \end{aligned}$$ From the above equation, $u = \frac{1}{2}(x + y)$ and $v = \frac{1}{2}(x - y)$. Therefore $$\frac{\partial (u, v)}{\partial (x, y)} = \det \begin{pmatrix} \frac{1}{2} & \frac{1}{2} \\ \frac{1}{2} & -\frac{1}{2} \end{pmatrix} = -\frac{1}{2} \to \Big| \frac{\partial (x, y)}{\partial (u, v)} \Big| = 2 $$ $$\iint_D \sqrt{x^2 - y^2} \, dydx = 2\iint \sqrt{uv} \cdot 2 \, dudv = 4 \int_0^1\int_0^u \sqrt{u} \sqrt{v} \, dudv $$ \end{example} 
 \begin{example} One Variable Version, known as U-Substitution $$\begin{aligned} 
 \int_1^2 x\sqrt{5 - x^2} \, dx &= \\ u &= 5 - x^2 \\ I = [1, 2] &\to I^* = [1, 4] \\ \int_I x\sqrt{5 - x^2} \, dx &= \int_{I^*} x\sqrt{u} \Big|\frac{dx}{du}\Big| \, du \\ \frac{du}{dx} = -2x &\to \Big| \frac{du}{dx} = 2x \\ \Big| \frac{dx}{du} \Big| &= \frac{1}{2x} \\ \int_{I^*} x\sqrt{u} \frac{1}{2x} \, du &= \int_1^4 \frac{1}{2} \sqrt{u} \, du \end{aligned} $$ \end{example} 
 \begin{definition} Change of Variables: Let $f$ be continuous (with the usual exceptions) and $D \to R$. Find a nice region $D^*$ and transformation $T: D^* \to D$ where $T$ is $C^1$ (with usual exceptions) and $T$ is bijection (with usual exceptions). Then $$\iint_D f(x, y) \, dA_{\{x, y\}} = \iint_{D^*} f \cdot T(u, v) \Big| \frac{\partial (x, y)}{\partial (u, v)}\Big|\, dA_{\{u, v\}} $$ \end{definition} 
 
 \begin{example} $$\iint_D (5x + 3y)^3(3x + 2y)^2 \, dA$$ where $T$ is the intersection of 3 points: (0, 0), (-1, 3) and (5, -7). \\ 
 $$\begin{aligned} u&= 5x + 3y \\ v &= 3x + 2y \\ T\begin{pmatrix} u \\ v \end{pmatrix} &= \begin{pmatrix} 5 & 3 \\ 3 & 2 \end{pmatrix} \begin{pmatrix} x \\ y \end{pmatrix} \end{aligned} $$ 
 Change of variables gives $$\iint_{D^*} u^3v^2 \Big| \frac{\partial (x, y)}{\partial (u, v)} \Big| \, dudv $$ Avoid solving for $x$, $y$ in terms of $u$, $v$ using Inverse Function Theorem. $$\frac{\partial (u, v)}{\partial (x, y)} = \det \begin{pmatrix} 5 & 3 \\ 3 & 2 \end{pmatrix} \to \frac{\partial (x, y)}{\partial (u, v)} = 1 $$ Solve for the given points in $u$, $v$ plane: $$\begin{tabular}{|c|c|} \hline ($x$, $y$) & ($u$, $v$) \\ \hline (0, 0) & (0 ,) \\ \hline (-1, 3) & (4, 3) \\ \hline (5, -7) & (4, 1) \\ \hline \end{tabular} $$ 
 Thus $$\iint_{D^*} u^3 v^2 \cdot 1 dA_{\{u, v\}} = \int_0^4 \int_{\frac{1}{4}u}^{\frac{3}{4}u} u^3v^2 \, dvdu $$ \end{example} 
 Note: Change of variables for regions in $\mathbb{R}^3$ have a $3 \times 3$ Jacobian determinant. 
 \begin{example} Spherical Coordinates: Let $\phi$ be the angle measured from the $z$ axis, $0 \leq \phi \leq \pi$. Then as an intermediate step, think of polar coordinates in the $x$, $y$ plane. Let $\theta$ be the angle from the $x$ axis, $0 \leq \theta \leq 2\pi$. Let $\rho$ be the distance from the origin to the point of interest, $\rho \geq 0$. Then $$\begin{aligned} r &= \rho \sin \phi \\ x &= r\cos \theta = \rho \sin \phi \cos \theta \\ y &= r\sin \theta = \rho \sin \phi \sin \theta \\ z &= \rho \cos \phi \end{aligned} $$ What is the Jacobian determinant? $$\frac{\partial (x, y, z)}{\partial (\rho, \theta, \phi)} = \rho^2 \sin \phi $$ \end{example} 
 \begin{example} Let $T: \mathbb{R}^2 \to \mathbb{R}^2$ where $T(x, y) = (2x, y)$. This is a transformation that stretches a 1 by 1 unit square horizontally by a factor of 2. Is it one to one? \\ Check if $T(x, y) = T(x', y')$. $$\begin{aligned} (2x, y) &= (2x', y') \\ x &= x' \\ y &= y' \end{aligned} $$ Another way to check is by setting up the the transformation matrix and checking its determinant. $$T = \begin{pmatrix} 2 & 0 \\ 0 & 1 \end{pmatrix} $$ If $\det T \neq 0$, then $T$ is isomorphism (both 1-1 and onto). \\ This transformation is indeed one to one. \end{example} 
 
 \begin{example} Let $T$ be the transformation $T(x, y) = (x^2, y)$. Is it one to one? \\ This transformation is a unit square on both the domain and codomain. Taking the piece of the transformation keeping $y$ constant, $T(x, 0) = (x^2, 0)$. On the diagonal axis, $T(x, x) = (x^2, x)$. Therefore this transformation is not one to one. $$\begin{aligned} T(x, y) &= T(x', y') \\ x^2 &= x'^2 \\ x &= \pm x' \end{aligned} $$ \end{example} 
 
 \begin{example} Solve this integral using a change of variables: $\iint_P (5x + y)^3(x + 9y)^4\, dA$ where $P$ is a parallelogram with vertices (0, 0), (9, -1), (-2, 10) and (7, 9). \\ Let $u = 5x + y$ and $v = x + 9y$. $$\begin{tabular}{|c|c|} \hline 
 $(x, y)$ & $(u, v)$ \\ \hline (0, 0) & (0, 0) \\ \hline (9, -1) & (44, 0) \\ \hline (-2, 10) & (44, 88) \\ \hline (7, 9) & (0, 88) \\ \hline \end{tabular} $$ 
 $$\iint_{R^*} u^3v^3 \Big| \frac{\partial (x, y)}{\partial (u, v)}\Big| \, dA$$ $$\begin{aligned} \Big| \frac{\partial (u, v)}{\partial (x, y)} \Big| &= \Big| \det \begin{pmatrix} 5 & 1 \\ 1 & 9 \end{pmatrix} \Big| = 44 \\ \Big| \frac{\partial (x, y)}{\partial (u, v)}\Big| &= \frac{1}{44} \end{aligned} $$ $$\int_0^{44} \int_0^{88} u^3v^3 \frac{1}{44} \, dvdu $$ \end{example} 
 
 \begin{example} Solve this integral using a change of variables: $\int_0^1 \int_0^{x^2} xy \, dydx = \iint_{D^*} f(u, v)\, dA$ where $D^*$ is a triangle in the $uv$ plane such that $0 < u < 1$ and $0 < v < u$. \\ Let $u = x$ and $v = \sqrt{y}$. (This problem can also be done where $u = x^2$ and $v = y$.) $u$ should depend on $x$ such that $x$ axis goes to $x$ axis: $(x, 0) \to (~,0)$. $v$ should depend on $y$: $(1, y) \to (1, ~)$. The line segment from 0 to 1 in the $x$ direction should go to some line segment. In addition, the line segment from $y = 0$ to $y = 1$ should also go to some line segment. $$\begin{pmatrix} u \\ v \end{pmatrix} = S\begin{pmatrix} x \\ y \end{pmatrix} = \begin{pmatrix} x \\ \sqrt{y} \end{pmatrix} $$ Check the image of the region $D$. On the $x$ axis, $S\begin{pmatrix} x \\ 0 \end{pmatrix} = \begin{pmatrix} x \\ 0 \end{pmatrix}$ where $0 \leq x \leq 1$. On the $y$ axis, $S\begin{pmatrix} 1 \\ y \end{pmatrix} = \begin{pmatrix} 1 \\ \sqrt{y} \end{pmatrix}$ where $0 \leq y \leq 1$. On the parabola, $S\begin{pmatrix} x \\ x^2 \end{pmatrix} = \begin{pmatrix} x \\ x \end{pmatrix}$ wher $0 \leq x \leq 1$. 
 $$\begin{aligned} \int_0^1 \int_0^{x^2} xy \, dydx &= \iint_{D^*} uv^2 \Big| \frac{\partial (x, y)}{\partial (u, v)}\Big| \, dA \\ x &= u \\ y &= v^2 \\ \Big| \frac{\partial (x, y)}{\partial (u, v)} &= \Big| \det \begin{pmatrix} 1 & 0 \\ 0 & 2v \end{pmatrix} \Big| = 2v \end{aligned} $$ $$\int_0^1 \int_0^u  uv^2 \cdot 2v \, dvdu $$ \end{example} 
 
\begin{proof} Change of Variables: Let $T: D^* \to D$ where the boundary of $D^*$ are parameterized curves and $T$ is $C^1$ and bijection. Let $f: D \to R$ and its integral exists. $$\iint_D f(x, y) \, dA_{\{x, y\}} = \iint_{D^*} f \cdot T(u, v) \Big| \frac{\partial (x, y)}{\partial (u, v)} \Big| \, dA_{\{u, v\}} $$ Use the definition of integral by Riemann sums. Partition the $uv$  region into small squares $\delta R_{ij}$. Let $c_{ij}^*$ be a sample point in the little square $\delta R_{ij}$. Now transform to the $xy$ plane. On small square $\delta R_{ij}$, approximate $T$ by linear approximation: $$ \begin{pmatrix} x \\ y \end{pmatrix} = T(c_{ij}^*) + \mathds{D}T(c_{ij}^*) \cdot \begin{pmatrix} u \\ v \end{pmatrix} - \begin{pmatrix} u_0 \\ v_0 \end{pmatrix} $$ where $c_{ij}^* = (u_0, v_0)$. Note that the transformation does not affect area . The second term stretches the area by the absolute value of $\det (\mathds{D}T(c_{ij}^*))$. This gives a partition of region $D$ in $xy$ plane. In fact, $D = T(D^*)$. The partitions are approximately parallelograms, images of $\delta R_{ij}$. The area of the new parallelograms are approximately $ \Big| \frac{\partial (x, y)}{\partial (u, v)} \Big| (\text{ area of } \delta R_{ij})$. A sample point in the parallelogram is $T(c_{ij})$. Therefore $$ \iint_D f(x, y) \, dA_{\{x, y\}} = \lim \sum \underbrace{f(T(c_{ij}^*))}_{f(c_{ij})} \cdot \underbrace{\Big| \frac{\partial (x, y)}{\partial (u, v)} \Big| \cdot \text{ area of } \delta R_{ij}}_{\text{area in } xy \text{ plane}} $$ This is the definition of the integral. 
$$\iint_{D^*} f c\dot T(u, v) \Big| \frac{\partial (x, y)}{\partial (u, v)} \Big| \, dA_{\{u, v\}} $$ \end{proof} 

\begin{example} Let the points (0, 0), (1, 1), (2, 0), (1, -1) form a parallelogram in the $xy$ plane. Transform the points into a unit square in the $uv$ plane. \\ Matrix transformation from standard basis $e_1, e_2$ to arbitrary values $T(e_1)$ and $T(e_2)$ is given by $\begin{pmatrix} T(e_1) & T(e_2) \end{pmatrix}$. Find the transformation $T(e_1) = v_1$ and $T(e_2) = v_2$ where $v_1$ is the vector $(1, 1) \to (2, 0)$ and $v_2$ is the vector $(0, 0) \to (1, 1)$. Then $T = \begin{pmatrix} 1 & 1 \\ 1 & 1 \end{pmatrix}$. (The vectors are put into the matrix as column vectors.) Then the map of $D \to D^*$ is the inverse of $T$, namely $$\begin{aligned} \begin{pmatrix} x \\ y \end{pmatrix} &\to \begin{pmatrix} 1 & 1 \\ 1 & 1 \end{pmatrix}\begin{pmatrix} x \\ y \end{pmatrix} \\ &= \frac{1}{2} \begin{pmatrix} 1 & -1 \\ 1 & 1 \end{pmatrix} \begin{pmatrix} x \\ y \end{pmatrix} \end{aligned} $$ Therefore $$\begin{aligned} u &= \frac{1}{2}(x - y) \\ v &= \frac{1}{2}(x + y) \end{aligned} $$ \end{example} 

\begin{example} Perform a change of variables for the following integral. $$\iint_D (x + y)^2 e^{x - y} \, dA_{\{x, y\}}$$ where $D$ is the region bounded by $x + y = 1$, $x + y = 4$, $x - y = -1$ and $x - y = -1$. $$\begin{aligned} u &= x + y \\ v &= x - y \\ \Big| \frac{\partial (u, v)}{\partial (x, y)} &= \det \begin{pmatrix} 1 & 1 \\ 1 & -1 \end{pmatrix} = 2 \\ \Big| \frac{\partial (x, y)}{\partial (u, v)} \Big| &= \frac{1}{2} \end{aligned} $$ $$ \int_1^4 \int_{-1}^1 u^2 e^v \cdot \frac{1}{2} \, dvdu = \frac{21}{2}(e - \frac{1}{e}) $$ \end{example} 

\begin{example} Perform a change of variables for the following integral: $$\iiint_P (x + 2y)^3(2y + 3z)^4(x - 2z)^5 \, dV_{\{x, y, z\}} $$ where $P$ is generated by $v_1 = (4, -3, 2)$, $v_2 = (2, -1, 1)$ and $v_3 = (6, -3, 2)$. $$\begin{aligned} u &= x + 2y \\ v &= 2y + 3z \\ w &= x - 2z \\ \Big| \frac{\partial (u, v, w)}{\partial (x, y, z)} \Big| &= \det \begin{pmatrix} 1 & 2 & 0 \\ 0 & 2 & 3 \\ 1 & 0 & -2 \end{pmatrix} \\ \frac{\partial (x, y, z)}{\partial (u, v, w)} &= \frac{1}{2} \end{aligned} $$ $$\begin{tabular}{|c|c|c|c|} \hline & u & v & w \\ \hline $v_1$ & -2 & 0 & 0 \\ \hline $v_2$ & 0 & 1 & 0 \\ \hline $v_3$ & 0 & 0 & 2 \\ \hline \end{tabular} $$ $$\int_0^2 \int_0^1 \int_{-2}^0 u^3v^4w^5 \cdot \frac{1}{2} \, dudvdw $$ \end{example} 

Circumstances that are good for use of Spherical Coordinates: \begin{itemize} 
\item $\rho$ = constant (sphere) \item $\theta$ = constant (plane through origin) \item $\phi$ = constant (cone) \end{itemize} 

\begin{example} Let $R$ be the region above the cone $2z^2 = x^2 + y^2$ and below the upper hemisphere of $x^2 + y^2 + z^2 = a^2$. The density of $R$ is given by $\delta(x, y, z) = z$. Find its mass. \\ 
Requires the use of spherical coordinates. $$ \begin{aligned} \int_0^{2\pi} \int_0^{\arctan \sqrt{2}} \int_0^a \rho \cos \phi \cdot \rho^2\sin \phi \, d\rho d\phi d\theta &= \frac{1}{4} \rho^4 \Big|_0^a \cdot \frac{1}{2}\sin^2 \phi \Big|_0^{\arctan \sqrt{2}} \cdot \theta \Big|_0^{2\pi} \\ &= \frac{1}{4}a^4 \cdot \frac{1}{2}\Big(\frac{\sqrt{2}}{\sqrt{3}}\Big)^2 \cdot 2\pi \end{aligned} $$ \end{example}

If a constant force acts over a certain distance, then work = force $\cdot$ distance. Suppose a path is parameterized by a curve $\vec{c}(t)$. A force is given by a vector field. We need the component of $F$ in the direction of the path the particle is traveling in. Let $u$ = the unit vector in the direction of motion. Then the component in direction is $u = \Big| F \Big| \cos \theta = F \cdot \vec{v}$. Suppose the direction vector is $\vec{c}'(t)$. Add up total amount of work done on small segments delivered by the tangent vectors $$\begin{aligned} \text{Work } &= \int \text{Force } \cdot \Big| c'(t) \Big| \, dt \\ &= \int F \cdot \frac{c'(t)}{|c'(t)|} \Big| c'(t) \Big| \, dt \\ \int \vec{F} \cdot \vec{c}'(t) \, dt \end{aligned} $$ 
Formal Definition of Line Integral: Let $C$ be a parameterized curve, say $\vec{c}(t)$ where $t \in [t_0, t_1]$ and $\vec{c}'(t)$ continuous. Let $F$ be a vector field. Ten $$\int_c F \cdot d\vec{s} = \int_c F(\vec{c}(t)) \cdot \vec{c}'(t) \, dt $$ where $d\vec{s}$ represents infinitesimal part of tangent vector ($d\vec{s} = \vec{c}'(t) \, dt$). Temporarily, to make the parameterization explicit, write $\int_{\vec{c}(t)} F \cdot d\vec{s}$. The curve $C$ comes with an initial point $\vec{c}(t_0)$ and final point $\vec{c}(t_1)$. 
\begin{theorem} In favorable circumstances, with an oriented curve, this line integral does not depend on parameterization. \end{theorem} 
\begin{example} Let $F(x, y) = (xy, x + y)$ and $c$ be the arc of the parabola $y = 3 - 3x^2$ from (1, 0) to (0, 3). \\ Parameterization: $(x, 3 - 3x^2)$ from $x = 1 \to x = 0$ $$\begin{aligned} \int_c F \cdot ds &= \int F \cdot \vec{c}'(x) \, dx \\ &= \int_1^0 (xy, x + y) \cdot (1, -6x) \, dx \\ &= \int_1^0 \Big[ x(3 - 3x^2) + (x + 3 - 3x^2)(-6x) \Big] \, dx \end{aligned} $$ Note that $d\vec{s} = \vec{c}'(x) \, dx = (1, -6x) \, dx$. \\ New parameterization: $(\sqrt{\frac{3 - y}{3}}, y)$ from $y = 0 \to y = 3$ This gives the same value for the line integral. \end{example} 
Note: If $F = (P, Q, R)$ and curve $\vec{c}(t) = (x(t), y(t), z(t))$ then $d\vec{s} = (dx, dy, dz)$ and $$\int_c F \cdot d\vec{s} = \int P\, dx + Q\, dy + R\, dz $$ This is called the differential form. 
\begin{theorem} Suppose $\vec{c_1}(t_1)$ and $\vec{c_2}(t_2)$ are two parameterizations for the same oriented curve $C$ with $\vec{c_1}(t_1), \vec{c_2}(t_2)$ being bijective and $C^1$. Furthermore, assume $\vec{c_1}$ and $\vec{c_2}$ are never zero and $\vec{c_2}^{-1} \cdot \vec{c_1}$ is also $C^1$. Then $$\int_{\vec{c_1}} \vec{F} \cdot \, d\vec{s} = \int_{\vec{c_2}} \vec{F} \, d\vec{s} $$ \end{theorem} 

\begin{proof} Let $C$ be a curve that can be parameterized by both $\vec{c_1}$ and $\vec{c_2}$. $\vec{c_1}$ goes from point $a_1$ to $b_1$ in time $t_1$ while $\vec{c_2}$ goes from point $a_2$ to $b_2$ in time $t_2$. Orientation is the same, by assumption. So then $\vec{c_1}(a_1) = \vec{c_2}(a_2)$ which is the ``start'' on the curve and $\vec{c_1}(b_1) = \vec{c_2}(b_2)$ which is the ``end'' of the curve. Since $\vec{c_2}$ is bijective, it has an inverse function. Thus $h = \vec{c_2}^{-1} \cdot \vec{c_1}$ where $[a_1, b_1] \to [a_2, b_2]$. If so, $h(a_1) = a_2$ and $h(b_1) = b_2$. Assume $h$ is $C^1$. Therefore $\vec{c_1} = \vec{c_2} \cdot h$ (reparameterization). Let $u = h(t)$. $$\begin{aligned} \int_{\vec{c_1}} \vec{F} \cdot \, d\vec{s} &= \int_{a_1}^{b_1} \vec{F}(\vec{c_1}(t)) \cdot \vec{c_1}'(t) \, dt \\ &= \int_{a_1}^{b_1} \vec{F}(\vec{c_2}(h(t))) \cdot \vec{c_2}'(h(t))h'(t) \, dt \\ &= \int_{a_2}^{b_2} \vec{F}(\vec{c_2}(u)) \cdot \vec{c_2}'(u) \, du \\ &= \int_{\vec{c_2}} \vec{F} \cdot \, d\vec{s} \end{aligned} $$ \end{proof} 


\begin{example} Let $\vec{F} = xy\hat{i} + x^2\hat{j}$ and $C$ be the straight path from (1, 1) to (2, 4). Compute the line integral. \\ Paramterization $\vec{c_1}$: $y = 3x - 2$ from $x = 1$ to $x = 2$. Then $\vec{c_1}(x) = (x, 3x - 2)$.
$$\begin{aligned} \int_{\vec{c_1}} \vec{F} \cdot \, d\vec{s} &= \int_1^2 \vec{F}(x, 3x - 2) \cdot (1, 3) \, dx \\ &= \int_1^2 \Big(x(3x - 2), x^2\Big) \cdot \Big(1, 3 \Big) \, dx \\ &= \int_1^2 3x^2 - 2x + 3x^2 \, dx \\ &= 11 \end{aligned} $$ 
Parameterization $\vec{c_2}$: $(1, 1) + t(1, 3)$ where $x = 1 + t$ and $y = 1 + 3t$ from $t = 0$ to $t = 1$. Then $\vec{c_2}(t) = (1 + t, 1 + 3t)$. $$\begin{aligned} \int_{\vec{c_2}} \vec{F} \cdot \, d\vec{s} &= \int_0^1 \vec{F}(1 + t, 1 + 3t) \cdot (1, 3) \, dt \\ &= \int_0^1 \Big( (1 + t)(1 + 3t), (1 + t)^2\Big) \cdot (1, 3) \, dt \\ &= \int_0^1 (1 + t)(1 + 3t) + 3(1 + t)^2 \, dt \\ &= 11 \end{aligned} $$ \end{example} 
 
\begin{theorem} Fundamental Theorem of Calculus for Line Integrals: Suppose $F = \nabla f$ is a conservative vector field. In other words, $F$ is the gradient of $f$, where $f$ is $C^2$. If the parameterized curve $C$ is $C^1$ and goes from starting point $p$ to ending point $q$, then $$\int_C \vec{F} \cdot \, d\vec{s} = f(q) - f(p) $$ \end{theorem}
Warning: For $\vec{F}$ to be a vector field, it must be true that $\curl (\vec{F}) = \nabla \cdot \vec{F} = 0$. Not all vector fields are conservative. This theorem only applies when $F$ is conservative. When this theorem does apply, the answer only depends on the starting and ending point of $C$. 
\begin{proof} Let $\vec{F}: C \subseteq \mathbb{R}^3 \to \mathbb{R}^3$. By assumption, $\vec{F} = \nabla F$ where $f: C \to \mathbb{R}$ and $\nabla F = \mathds{D}f$ is a $1 \times 3$ vector. Consider the parameterization $\vec{C}: [a, b] \subseteq \mathbb{R} \to \vec{C} \subseteq \mathbb{R}^2$. Let $\vec{c}'(t)$ be a $3 \times 1$ vector. Let $g(t) = f(\vec{c}(t))$. By the chain rule, $$ g'(t) = \mathds{D}f(\vec{c}(t)) \cdot \vec{c}'(t) = \nabla f(\vec{c}(t)) \cdot \vec{c}'(t) = F(\vec{c}(t)) \cdot \vec{c}'(t) $$ Then $$\begin{aligned} \int_C \vec{F} \cdot \, d\vec{s} &= \int_a^b \vec{F}(\vec{c}(t)) \cdot \vec{c}'(t) \, dt \\ &= \int_a^b g'(t)\, dt \\ &= g(b) - g(a) \\ &= f(\vec{c}(b)) - f(\vec{c}(a)) \\ &= f(q) - f(p) \end{aligned} $$ where $\vec{c}(b)$ is the end point in $C$ and $\vec{c}(a)$ is the starting point in $C$. \end{proof} 

\begin{example} Solve the line integral $\int_C yz \, dx + xz \, dy + xy \,dz$ where $C$ is a piece-wise linear path connecting (1, 0, 0), (0, 1, 0) and (0, 1, 0), (0, 0, 1). \\ Note: If $\vec{s} = (x, y, z)$, then $d\vec{s} = (dx, dy, dz)$ and so $\vec{F} = (yz, xz, xy)$. \\
On the first segment, $(x, y, z) = (1, 0, 0) + t(-1, 1, 0)$. Therefore $x = 1 - t$, $y = t$ and $z = 0$, from $t = 0$ to $t = 1$. 
$$\int_I 0y \,dx + 0x \, dy + xy\, (0) = 0 $$ 
On the second segment, $(x, y, z) = (0, 1, 0) + t(0, -1, 1)$ from $t = 0$ to $t = 1$. 
$$\int_I yz \, (0) + 0z \, dy + 0y \, dz = 0 $$ 
Therefore $$|int_C \vec{F} \cdot \, d\vec{s} = 0 $$ \\~\\
Using the FTOC, if $F = \nabla f$, then $f = xyz$ and so $$\int_C \vec{F} \cdot \, d\vec{s} = f(0, 0, 1) - f(1, 0, 0) = 0 $$ 
For fun, suppose $(x, y, z) = (1 - t, t - t^2, t^3)$ is another parameterization, from $t = 0$ to $t = 1$. $$\begin{aligned} \int_{\vec{c_3}} \vec{F} \cdot \, d\vec{s} &= \int_0^1 \Big[ (t - t^2)t^3(-1) + (1 - t)t^3(1 - 2t) + (1 - t)(t - t^2)3t^2\Big] \, dt \\ &= \int_0^1 4t^3 - 10t^4 + 6t^5 \, dt \\ &= 0 \end{aligned} $$ \end{example}

\begin{example} Let $\vec{c}(t)$ be a path and $\vec{T}$ be a unit tangent vector. What is $\int_{\vec{c}} \vec{T} \, d\vec{s}$?  
$$\begin{aligned} \vec{T} = \frac{\vec{c}'(t)}{||\vec{c}'(t)||} \\ \int_{\vec{c}} \vec{T} \cdot \, d\vec{s} &= \int_a^b \frac{\vec{c}'(t)}{||\vec{c}'(t)||} \cdot \vec{c}'(t) \, dt \\ &= \int_a^b \frac{||\vec{c}'(t)||^2}{||\vec{c}'(t)||} \, dt \\ &= \int_a^b ||\vec{c}'(t)|| \, dt \end{aligned} $$ This is the length of little tangent vectors adding up to the length of a curve. \end{example} 
Note: The line integral of a unit tangent vector on curve $C$ gives the length of the curve. \\~\\
If $\vec{s}$ is a vector piece of a curve, and $\vec{c}(t)$ is a parameterized curve, then $\vec{s} = \vec{c}(t)$ and $d\vec{s} = \vec{c}'\, dt$. if $s$ = arc length, $ds = ||\vec{c}'(t) ||\, dt$. 

\begin{example} Solve the following integral using change of variables $$\int_B (x + y) \, dA_{x, y}$$ where $B$ is the rectangular region $P(0, 1)$, $Q(1, 0)$, $R(3, 4)$ and $S(4,3)$. \\ Simplify by change of variables. $$\begin{aligned} PR: y &= x + 1 \\ QS: y &= x - 1 \\ PQ: y &= -x + 1 \\ RS: y &= -x + 7 \end{aligned} $$ 
Form a rectangular in the $uv$ region with sides parallel to the axis. Look for boundaries of form $u =$ constant and $v = $ constant. $$ \begin{aligned} u &= y - x \to PR: u = 1, ~ QS: u = -1 \\ v &= y + x \to PQ: v = 1, ~ RS: v = 7 \\ \Big| \frac{\partial (x, y)}{\partial (u, v)}\Big| &= \Big| \frac{\partial (u, v)}{\partial (x, y)}\Big|^{-1} \\ &= \Big| \det \begin{pmatrix} -1 & 1 \\ 1 & 1 \end{pmatrix} \Big|^{-1} \\ &= | -1 - 1 |^{-1} = |(-2)|^{-1} \\ &= \frac{1}{2} \end{aligned} $$ Thus the integral becomes $$\int_{-1}^1 \int_1^7 v \cdot \frac{1}{2} \,dvdu $$ \end{example} 

\begin{example} Let $R$ be the region within the cone $z = \sqrt{3(x^2 + y^2)}$ between the upper hemisphere $x^2 + y^2 + z^2 = 1$ and $x^2 + y^2 + z^2 = 9$. The density $\delta(P)$ at each point $P$ in $R$ is inversely proportional to the distance from $P$ to the origin. Find the mass of $R$. \\ 
Mass of Sphere: $1 \leq \rho \leq 3 $; In the $yz$ plane, $z = \pm y\sqrt{3}$ and $\phi = \arctan\Big(\frac{1}{\sqrt{3}}\Big) = \frac{\pi}{6} $. Thus $0 \leq \phi \leq \frac{\pi}{6}$ and $0 \leq \theta \leq 2\pi$. \\ Alternatively, $$\begin{aligned} z &= \rho \cos \phi \\ x^2 + y^2 &= \rho^2 \\ r &= \rho \sin \phi \end{aligned} $$ Put this into the equation of the cone $$ z = \rho \cos \phi = \sqrt{3}\rho\sin\phi \to \arctan \phi = \frac{1}{\sqrt{3}} \to \phi = \frac{\pi}{6} $$ This is another way to find an expression of a cone in spherical coordinates. $$\int_0^{2\pi} \int_0^{\frac{\pi}{6}} \int_1^3 \underbrace{\frac{k}{\rho}}_{\delta(\rho)} \, \rho^2 \sin \phi \, d\rho d\phi d\theta $$ \end{example} 

\begin{example} The path $t \to (\cos^3 t, \sin^3 t)$, $0 \leq t \leq 2\pi$, is called a hypocycloid. Evaluate the integral of the vector field $\vec{F}(x, y) = x\hat{i} + y\hat{j}$ around this curve. \\ Start at $c(0) = (1, 0)$ and end at $(1, 0)$. To be safe, you might have to do parameterization on each regular piece since the graph has 4 cusps, each at an axis. $$\begin{aligned} \int_C \vec{F} \cdot \, d\vec{s} &= \int_C x\, dx + y\, dy \\ &= \int_0^1 (\cos^3 t, \sin^3 t) \cdot (-3\cos^2 t\sin t, 3\sin^2 t\cos t) \, dt \\ &= -3 \int_0^1 \cos^5t\sin t - \sin^5\cos t \, dt = 0 \end{aligned} $$ Alternatively, without knowing the antiderivative, call it $g(t)$. $$\int_C \vec{F} \cdot d\vec{s} = [g(\frac{\pi}{2}) - g(0)] + [g(\pi) - g(\frac{\pi}{2})] + [g(\frac{3\pi}{2}) - g(\pi)] + [g(2\pi) - g(\frac{3\pi}{2})] = 0 $$ Better trick if $F = x\hat{i} + y\hat{j}$ is a conservative vector field ($F = \nabla f$): By eyeballing the equation, it is easy to see that $f = \frac{1}{2}(x^2 + y^2)$. Thus when $F$ is conservative, $\int_C \vec{F} \cdot \, d\vec{s}$ does not depend on $C$ but only the starting and ending point. In particular, on a curve when starts and ends at the same place, $$\int (\text{conservative vector field}) \cdot \, d\vec{s} = 0 $$ \end{example} 

\begin{example} Let $F = (z^3 + 2xy)\hat{i} + x^2\hat{j} + 3xz^2\hat{k}$. Show that the integral of $F$ around the circumference of the unit square with vertices $(\pm 1, \pm 1, \pm 1)$ is zero. \\ The lack of information about precise curve $C$ suggests that $F$ is conservative. Check for ``conservative'' - curl $F = 0$. This is necessary for $F$ to have a potential function but it isn't sufficient unless we know something more about the region of integration. Let's review how to produce $f$: $$ \begin{aligned} f_x &= z^3 + 2xy \\ f &= xz^3 + x^2y + g(y, z) \\ f_y &= x^2 + \frac{\partial g}{\partial y} = x^2 \\ \frac{\partial g}{\partial y} &= 0 + h(z) \\ f &= xz^3 + x^2y + h(z) \\ f_z &= 3xz^2 + h'(z) = 3xz^2 \\ h'(z) &= 0 + c \\ f &= xz^3 + x^2y + c \end{aligned} $$ Constants of integration cancels whenever we do f(end) - f(start). Thus the line integral is zero. \end{example} 

Surface Integral: A surface is a 2D object in $\mathbb{R}^3$ which can be described as: \begin{enumerate} 
\item graph of $g(x, y)$ where $g: D \subseteq \mathbb{R}^2 \to \mathbb{R}^3$. Then points in the surface have the form $(x, y, g(x, y))$. \item level set of $f$ where $f: D \to \mathbb{R}^3$ and $f(x, y, z) = $ constant. The normal direction to the level set is given by $\nabla f$ at a point $P$ on the level set. Think of $z = g(x, y)$ as a level set $g(x, y) - z = 0$. The normal for this new form of the function is $(\frac{\partial g}{\partial x}, \frac{\partial g}{\partial y}, -1)$. \item parameterized curve where $\Phi: D \subseteq \mathbb{R}^2 \to \mathbb{R}^3$ and surface $\Phi(D) = S$ or $\Phi(x, y) = (x, y, z)$. This is a generalization of the graph. \end{enumerate} 
Sphere of constant radius $a$: $$ \begin{aligned} x &= a\sin \phi \cos \theta \\ y &= a\sin \phi \sin \theta \\ z &= a\cos \phi \end{aligned} $$ This maps $(\theta, \phi)$ to a sphere. \\ 
Cylinder of constant radius $a$: $$ \begin{aligned} x &= a\cos \theta \\ y &= a\sin \theta \\ z &= z \end{aligned} $$ This maps $(\theta, z)$ to a cylinder. \\ 
Regular surfaces have nonzero normal at each point. It is $C^1$ and bijective so that the surface is only covered once. To find the normal to a point on a parameterized curve $$\begin{aligned} u-\text{curve says } &\Phi(u, v_0) \text{ where we let } v = v_0 \text{ constant and let } u \text{ vary } \\ v-\text{curve says } &\Phi(u_0, v) \text{ where we let } u = u_0 \text{ constant and let } v \text{ vary } \end{aligned} $$ By linear approximation around $P(u_0, v_0)$, $$\Phi(u, v) = \Phi(P) + \mathds{D}\Phi(P)\begin{pmatrix} u - u_0 \\ v - v_0 \end{pmatrix} $$ The tangent vector to the $u$ curve is $T_u = \Big( \frac{\partial x}{\partial u}, \frac{\partial y}{\partial u}, \frac{\partial z}{\partial u}\Big)$. The tangent vector to the $v$ curve is $T_v = \Big( \frac{\partial x}{\partial v}, \frac{\partial y}{\partial v}, \frac{\partial z}{\partial v}\Big)$. Use the idea that the cross product of two vectors is perpendicular to both of them to produce normal direction $T_u \times T_v$ to the parameterized surface $S$. The surface is regular at $P$ if $T_u \times T_v \neq 0$ at $P$. The rectangle in the $uv$ plane with small sides has area $\Delta u \Delta v$. Take a patch by applying $\Phi$ to the small rectangles, in other words, approximate the parallelogram in surface $S$. Then $$\text{Area of parallelogram } = (|T_u| \Delta u)(|T_v| \Delta v) \underbrace{\sin \theta}_{\text{between }T_u, ~T_v} = ||T_u \times T_v|| \Delta u \Delta v $$ 
If $S$ is a parameterized surface, we think of a little patch on surface as $d\vec{s} = (T_u \times T_v) \, dA_{uv}$. The area of this surface is $ds = ||T_u \times T_v || \, dA_{uv} $. Analogously, with line integrals for a curve parameterized by $\vec{c}(t)$: $d\vec{s} = \vec{c}'(t) \, dt$ is little tangent lines along the curve and $ds = || \vec{c}'(t) || \, dt$ is the length of the curve. \\
Surface Integral: $$\iint_S \vec{F} \cdot \, d\vec{s} = \iint_S \vec{F}(\Phi(u, v)) \cdot (T_u, T_v) \, dA_{uv} $$ where $S$ is a parameterized surface. and $(x, y, z) = \Phi(u, v)$ gives the parameterization of the surface $S$. In general, this surface integral does not depend on a choice of nice parameterization $\Phi$. We also have $$\iint_S f\, d\vec{s} = \int_S f \cdot ||T_u \times T_v|| \, dA_{uv} $$ If $f = 1$, you get the area of the surface. \\
Spherical parameterization of constant radius $a$: $T_{\phi} \times T_{\theta} = a\sin \phi(x, y, z)$ at a point $(x, y, z)$ on the sphere of radius $a$. Then $|T_{\phi} \times T_{\theta}| = a\sin \phi \cdot a = a^2 \sin \phi$. \\
Cylindrical parameterization of constant radius $a$: $T_{\theta} \times T_z = $, and $|T_{\theta} \times T_z| = a$. \\ Hint: Use $T_u = \Big( \frac{\partial x}{\partial u}, \frac{\partial y}{\partial u}, \frac{\partial z}{\partial u} \Big)$, $T_v = \Big( \frac{\partial x}{\partial v}, \frac{\partial y}{\partial v}, \frac{\partial z}{\partial v} \Big)$ and so $T_u \times T_v = \Big( \frac{\partial (y, z)}{\partial (u, v)}, \frac{\partial (x, z)}{\partial (u, v)}, \frac{\partial (x, y)}{\partial (u, v)} \Big)$. 

\begin{example} Let $\Phi(u, v) = (u + v, u - v, 2uv)$. Then $$\begin{aligned} T_u &= (1, 1, 2v) \\ T_v &= (1, -1, 2u) \\ T_u \times T_v &= (2(u + v), -2(u - v), -2) = (2x, -2y, -2) \end{aligned} $$This is the same as the level set to $x^2 - y^2 = 2z$ whose level set is $x^2 - y^2 - 2z = 0$. In fact, the normal, or gradient, is $(2x, -2y, -2)$. \end{example} 

Parameterized Surface: Let $(x, y, z) = \Phi(u, v)$. Then the normal to the surface is $T_u \times T_v$ at a point $P$ on the surface where $T_u = \Big( \frac{dx}{du}, \frac{dy}{du}, \frac{dz}{du} \Big)$ and $T_v = \Big( \frac{dx}{dv}, \frac{dy}{dv}, \frac{dz}{dv} \Big)$.  
\begin{example} Find an equation for the plane tangent to $x = u^2 - v^2$, $y = u + v$, $z = u^2 + 4v$ at $\Big( -\frac{1}{4}, \frac{1}{2}, 2 \Big) $. $$\begin{aligned} T_u &= (2u, 1, 2u) \\ T_v &= (-2v, 1, 4) \\ T_u \times T_v &= (4 - 2u, -(8u + 4uv), 2u + 2v) \end{aligned} $$ What is $u, v$ at $P$? $$\begin{aligned} u^2 - v^2 &= -\frac{1}{4} \\ (u - v)(u + v) &= -\frac{1}{4} \\  u + v &= \frac{1}{2} \\ \frac{1}{2}(u - v) &= -\frac{1}{4} \\ u - v &= =\frac{1}{2} \\ u &= 0 \\ v &= \frac{1}{2} \end{aligned} $$ Therefore $$T_u \times T_v = (4 - 2(0), -(8(0) + 4(0)(\frac{1}{2})), 2(0) + 2(\frac{1}{2})) = (4, 0, 1) $$ The equation of the plane is $$N \cdot ((x, y, z) - P) = 0 $$ or $$4(x + \frac{1}{4}) + (z - 2) = 0 $$ At what points is the surface regular? \\ We want the normal vector at a regular point not to be zero. Therefore $$\begin{aligned} 4 - 2u &= 0 \\ 8u - 4uv &= 0 \\ 2u + 2v &= 0 \end{aligned} $$ From this, $u \neq -2$ and if $v = -2$, then $u \neq 0$. The point where $u = 2$ and $v = 2$ shows irregularity. Thus the point at $(2, -2, -4)$ is not regular. \\ Note: Choice of normal direction will determine ``orientation'' (inside to outside, etc). \end{example} 
Scalar Surface Integral: $\iint F \, dS $ where $dS = ||T_u \times T_v || \, dA_{uv} $ \\ 
Vector Surface Integral: $\iint \vec{F} \cdot d\vec{S}$ where $d\vec{S} = (T_u \times T_v) \, dA_{uv} $ \\
Special case is scalar surface integral when $f = 1$; then $\iint dS = $ area of surface. 

\begin{example} Let $\Phi(u, v) = (e^u \cos v, e^u \sin v, v)$ be a mapping from $D = [0, 1] \times [0, \pi]$ in the $uv$ plane onto a surface $S$ in the $xyz$ space. Find $T_u \times T_v$. Find the equation for the tangent plane to $S$ when $(u, v) = (0, \frac{\pi}{2})$, Find the area of $\Phi(D)$. $$\begin{aligned} T_u &= (e^u \cos v, e^u \sin v, 0) \\ T_v &= (-e^u \sin v, e^u \cos v, 1) \\ T_u \times T_v &= (e^u \sin v, -e^u \cos v, e^{2u}) \end{aligned} $$ 
At (u, v) = $(0, \frac{\pi}{2})$, $(x, y, z) = (1, 0, 1)$ Therefore the tangent plane is $$(x - 0) + (z - \frac{\pi}{2}) = 0$$ 
$$\begin{aligned} \text{Area } &= \iint \, dS \\ &= \iint_D ||T_u \times T_v|| \, dA_{uv} \\ &= \iint_D e^u \sqrt{1 + e^{2u}} \, dA_{uv} \\ &= \int_0^1 \int_0^{\pi} e^u \sqrt{1 + e^{2u}} \, dvdu \end{aligned} $$ \end{example} 
Relationship between Scalar and Vector Surface Integral: Let the unit normal (at a regular point) be $\vec{n} = \frac{T_u \times T_v}{||T_u \times T_v||} $. Then $$\iint \vec{F} \, d\vec{S} = \iint (\vec{F} \cdot \vec{n}) \, dS$$
Interpretation of Vector Surface Integral: Suppose $\vec{F}$ gives the velocity of a fluid. A patch is a little piece of tangent plane to the surface. At $P$, resolve the velocity vector $\vec{F}$ into the component in direction of the unit normal $\vec{n}$ and the component in the tangent plane. How much of the fluid passes through the surface per unit time? In the direction of $\vec{n}$, we get $\vec{F} \cdot \vec{n}$. As a result, we get $$\iint \vec{F} \cdot \vec{n} \, dS = \text{Flux} $$ 
\begin{example} Let $(x, y, z) = (u + v, u - v, 2uv)$. Then $T_u \times T_v = 2(u + v, -(u - v), -1)$. Let the force be a radial vector field $Ix, y, z) = (x, y, z)$. Find the flux in the region $D: 0 \leq u \leq 1, 0 \leq v \leq 2$. 
$$\iint F \cdot \, dS = \iint (u + v, u - v, 2uv) \cdot 2(u + v, -(u - v), -1) \, dA_{uv} = 2\int_0^1 \int_0^2 \Big[ (u + v)^2 - (u - v)^2 - 2uv \Big] \, dvdu = 4 $$ \end{example} 

\begin{example} Consider the gravitational force field defined for $(x, y, z) \neq (0, 0, 0)$ by $\vec{F}(x, y, z) = -\frac{1}{(x^2 + y^2 + z^2)^{\frac{3}{2}}}(x\hat{i} + y\hat{j} + z\hat{k}) $. Show that the work done by the gravitational force as a particle moves from $(x_1, y_1, z_1)$ to $(x_2, y_2, z_2)$ along any path depends only on the radii $R_1 = \sqrt{x_1^2 + y_1^2 + z_1^2} $ and $R_2 = \sqrt{x_2^2 + y_2^2 + z_2^2}$. \\ Idea: Since no path is specified, hope for a conservative vector field. Find the potential function. Note from before that $f(\vec{r}) = \frac{1}{||\vec{r}||}$ (or $f(x, y, z) = \frac{1}{(x^2 + y^2 + z^2)^{\frac{1}{2}}}$). $$\text{Work} = \int \vec{F} \cdot \, d\vec{S} = f(R_2) - f(R_1) = \frac{1}{R_2} - \frac{1}{R_1} $$ \end{example} 

Generalization of Fundamental Theorem of Calculus for Line Integrals: $$ \begin{aligned} \int_a^b f(x) \, dx &= f(b) - f(a) \\ \int_{\text{start}}^{\text{end}} \underbrace{\vec{F}}_{\text{conservative vector field}} \cdot \, d\vec{S} &=  f(\text{end}) - f(\text{start}) \end{aligned} $$ 
Fundamental Theorem of Calculus for Double Integrals: $$\int_{\partial D} P \, dx + Q \, dy  = \iint_D (Q_x - P_y) \, dA_{xy} $$ Region $D$ should be a $xy$-simple region in the $xy$ plane ($y_2 = \Phi_2(x)$, $y_1 = \Phi_1(x)$). Set up as a $dydx$ integral. That region is also $y$-simple ($x = \Phi_2(y)$, $x = \Phi_1(y)$). We want the region to have a nice piecewise smooth $C^1$ boundary $\partial D$. Choose the direction along the boundary, keeping the region to your left as you walk around. This is Green's Theorem. 
\begin{example} Let the triangle region $D$ be formed by straight lines connecting the points (0, 0), (2, 0) and (0. 3). Find the line integral of $F = (x - 2y, 3x + 4y)$. \\ Parameterization of $(0, 0) \to (2, 0)$: $(x, 0)$ from $x = 0$ to $x = 2$. Thus $$\int_0^2 P\, dx + 0 = \int_0^2 x \, dx = 2 $$ 
Parameterization of $(2, 0) \to (0, 3)$: $y = -\frac{3}{2}x + 3$ from $x = 2$ to $x = 0$
$$\int_2^0 (-4x + 6) \, dx + (-3x + 12)(-\frac{3}{2}) \, dx = 23 $$ 
Parameterization of $(0, 3) \to (0, 0)$: $(0, y)$ from $y = 3$ to $y = 0$ $$\int_3^0 y \, dy = -4.5 $$ 
Thus the line integral is 2 + 23 - 4.5 = 21.5. 
$$\int_{\partial D} P \, dx + Q \, dy = \iint_D (Q_x - P_y) \, dA_{xy} = \int_{\triangle} 5 \, dA_{xy} = 5(\text{area of triangle}) = 5 \cdot \frac{1}{2} \cdot 2 \cdot 3  = 15 $$ \end{example} 

\begin{example} Consider the closed surface $S$ consisting of the graph $z = 1 - x^2 - y^2$ with $z \geq 0$ and also the unit disc in the $xy$ plane. Give this surface an outer normal. Compute $\iint_S \vec{F} \cdot \, d\vec{S}$ where $\vec{F}(x, y, z) = (2x, 2y, z)$. \\ Parameterize parabolic surface as a graph: $\Phi(x, y) = (x, y, 1 - x^2 - y^2)$. $$\begin{aligned} T_x &= (1, 0, -2x) \\ T_y &= (0, 1, -2y) \\ T_x \times T_y &= (2x, 2y, 1) \end{aligned} $$ Important for normal when surface is parameterized as a graph: $z = g(x, y) = 1 - x^2 - y^2$. $$\begin{aligned} T_x &= (1, 0, \frac{\partial g}{\partial x}) \\ T_y &= (0, 1, \frac{\partial g}{\partial y}) \\ T_x \times T_y &= (-\frac{\partial g}{\partial x}, -\frac{\partial g}{\partial y}, -1) \\ &= \nabla (z - g(x, y)) \end{aligned} $$ 
This agrees with the fact that the gradient is perpendicular to the level set. This choice is normal is ``outward'' for the paraboloid. The vector surface integral is thus: $$\begin{aligned} \iint_S \vec{F} \cdot \, d\vec{S} &= \iint_D (2x, 2y, z) \cdot (2x, 2y, 1) \, dA_{xy} \\ &= \iint_D 4x^2 + 4y^2 + \underbrace{z}_{1 - x^2 - y^2} \, dA_{xy} \\ &= \iint_D 3x^2 + 3y^2 + 1 \, dA_{xy} \\ \int_0^{2\pi} \int_0^1 3r^2 + 1 \, rdrd\theta \end{aligned} $$ 
A disk is a surface. Parameterize it by polar form: $$\begin{aligned} \Phi(r, \theta) &= (r\cos \theta, r\sin \theta, 0) \\ T_r &= (\cos \theta, \sin \theta, 0) \\ T_{\theta} &= (-r\sin \theta, r\cos \theta, 0) \\ T_r \times T_{\theta} &= (0, 0, r) \end{aligned} $$ This certainly is perpendicular to the $xy$ plane but it is inward. Thus to get normal, take the inverse, $(0, 0, -r)$. $$\int_0^{2\pi} \int_0^1 (2x, 2y, 0) \cdot (0, 0, -r) \, dA_{r, \theta} = 0 $$ \end{example} 
Spherical Coordinates: if $\rho_0$ is constant, $T_{\phi} \times T_{\theta} = \rho_0 \sin \phi(x, y, z) \to ||T_{\phi} \times T_{\theta} || = \rho_0 \sin \phi \cdot \rho_0 = \rho_0^2 \sin \phi $
Polar Coordinates: if $z_0$ is constant, $T_r \times T_{\theta} = (0, 0, r) \to ||T_r \times T_{\theta}|| = r $ \\
Another way to interpret vector surface integral is to use unit normal $\vec{n}$ to the surface. Then $$\iint \vec{F} \cdot \, d\vec{S} = \iint (\vec{F} \cdot \vec{n}) \, dS $$ If we use ``obvious'' unit normal outward, from base, $\vec{n} = (0, 0, -1)$ in the above example. Then $\vec{F} \cdot \vec{n} = 0$ (using $z = 0$ in the $xy$ plane). 

\begin{example} Let $\vec{F}(x, y, z)$. Evaluate $\iint_S \vec{F} \cdot \, d\vec{S}$ where $S$ is the upper hemisphere of radius 3, centered at the origin. \\ 
Spherical Coordinates: $T_r \times T_{\theta} = \rho_0 \sin \phi (x, y, z) = 3\sin \phi (x, y, z)$ 
$$\begin{aligned} \iint_S \vec{F} \cdot \, d\vec{S} &= \iint (x, y, z) \cdot (3\sin \phi(x, y, z)) \, dA_{\phi, \theta} \\ &= \iint 3\sin \phi \underbrace{(x^2 + y^2 + z^2)}_{\rho_0^2} \, dA_{\phi, \theta} \\ &= \iint 3 \cdot 3^2 \sin \phi \, dA_{\phi, \theta} \\ &= 27 \int_0^{2\pi} \int_0^{\frac{\pi}{2}} \sin \phi \, d\phi d\theta \end{aligned} $$ Note that $$ dS = ||T_{\phi} \times T_{\theta} || d\phi d\theta = \rho_0^2 \sin \phi d\phi d\theta $$ 
Alternatively, use the well-known unit normal $\vec{n}$ instead: $\vec{n} = \frac{(x, y, z)}{||(x, y, z)||} = \frac{1}{3}(x, y, z)$ Then $$\begin{aligned} \iint \vec{F} \cdot d\vec{S} &= \iint (\vec{F} \cdot \vec{n}) \, dS \\ &= \iint \frac{1}{3}(x^2 + y^2 + z^2) \, dS \\ &= \iint 3 \, dS \\ &= 3 \Big(\frac{1}{2}4 \pi 3^2 \Big) \\ &= 54 \pi \end{aligned} $$ \end{example}

\begin{theorem} Green's Theorem: Let $D$ be a $xy$-simple region. Let $\partial D^+$ be a boundary with positive orientation. If the vector field is $\vec{F} = (P, Q)$ in $\mathbb{R}^2$, then $$\iint_D (Q_x - P_y) \, dA_{xy} = \int_{\partial D^+} P \, dx + Q \, dy $$ \end{theorem} 

\begin{proof} Idea: Take a $x$-simple region. Show that $$\begin{aligned} \iint_D P_y \, dydx &= \int_a^b \int_{\phi_1(x)}^{\phi_2(x)} \frac{\partial F}{\partial y} \, dydx \\ &= \int_a^b F(x, y)\Big|_{\phi_1(x)}^{\phi_2(x)} \, dx \\ &= \int_a^b F(x, \phi_2(x)) \, dx - \int_a^b F(x, \phi_1(x)) \, dx \end{aligned} $$ by the fundamental theorem of calculus. \\
The other side of Green's Theorem involves line integral around $\partial D^+$ for $\int_{\partial D^+} P \, dx$. Parameterize the rightmost vertical line as $(a, y)$ where $x = $ constant. Then $dx = 0$. For the line on top, parameterize it as $(x, \phi_2(x))$. Then $\int_b^a P(x, \phi_2(x)) \, dx$. For the leftmost vertical line, $dx = 0$. For the line on the bottom, parameterize it as $(x, \phi_1(x))$. Then $\int_a^b P(x, \phi_1(x)) \, dx$. Note that $$\int_b^a P(x, \phi_2(x)) \, dx = -\int_a^b P(x, \phi_2(x)) \, dx$$ It follows that $$\int_a^b P(x, \phi_1(x)) \, dx = -\int_{\partial D^+} P \, dx $$ \end{proof} 

Green's Theorem can be applied to other regions that can be partitioned into $xy$-simple pieces. Apply Green's Theorem on each piece. All integrals on the cuts will be cancelled out. One can also use the limiting idea to extend Green's Theorem to even more general regions if $\partial D$ is nice. 

\begin{example} Let $D$ be the annulus by radius $R_2$ and small radius $R_1$ where $R_1 < R_2$. $$\begin{aligned} \int_{\partial D^+} (x^2 - 2y) \, dx + (y^2 + 5y) \, dy &= \int_D (Q_x - P_y) \, dA_{xy} \\ &= \iint_D (5 + 3) \, dA_{xy} \\ &= 8 \cdot \pi(R_2^2 - R_1^2) \end{aligned} $$ \end{example} 

Suppose $F = \nabla f$ (gradient vector field). Then $(P, Q) = (f_x, f_y)$. One side of Green's Theorem is an area integral. $$\iint (Q_x - P_y) \, dA_{xy} = 0 $$ This is since mixed partials are equal if we assume $f$ is $C^2$. The other side of Green's Theorem is a line integral. $$\int_{\partial D^+} P \, dx + Q \, dy = \int (\nabla f) \, d\vec{S} = f(\text{end}) - f(\text{begin}) = 0 $$ on a closed curve. 

\begin{theorem} Stoke's Theorem: Work with region $D$ in a $uv$ plane where Green's Theorem applies. Let $\partial D^+$ be the boundary of $D$ with positive orientation. Assume the boundary is parameterized by a $C^1$ function $c(t) = (u(t), v(t))$. Let $\Phi: D \to \mathbb{R}^3$ be bijective on $\partial D$ so that it induces a parameterization of $\partial S = \Phi(\partial D)$. Thus $\Phi \cdot c(t)$ denotes $\partial S$. Let $F$ be a vector field on a neighborhood of $S$ in $\mathbb{R}^3$ and $C^1$ except possible finitely many points. Then $$\iint_S \curl(F) \, d\vec{S} = \int_{\partial S^+} F \cdot \, d\vec{s} $$ \end{theorem} 

\begin{example} Use region $D$ in two dimensions as a region on the $xy$-plane. This means that $\Phi$ is the from transformation $(x, y) \to (x, y, 0)$ where $(x, y)$ is in $D \subseteq \mathbb{R}^2$ and $(x, y, 0)$ is on the $xy$ plane in $\mathbb{R}^3$ such that $z = 0$. Here $$\begin{aligned} \curl (F) &= (~, ~, Q_x - P_y) \\ T_x &= (1, 0, 0) = \hat{i} \\ T_y &= (0, 1, 0) = \hat{j} \\ T_x \times T_y &= \hat{k} \end{aligned} $$ 
In the LHS of Stoke's theorem: $$\iint Q_x - P_y \, dA_{xy}$$ In the RHS of Stoke's theorem: $$F \cdot d\vec{s} = F \cdot (dx, dy, dz) = P\, dx + Q\, dy + R\, dz $$ But $z$ is constant 0 on $xy$ plans and so $$F \cdot d\vec{s} = P\, dx + Q\, dy $$ This recovers Green's Theorem. \end{example} 

\begin{example} Let $z = 4 - x^2 - y^2$ be a paraboloid. Let its graph be a surface on $\mathbb{R}^3$. Compute the line integral. \\ Parameterize as a graph: $\Phi(x, y) = (x, y, 4 - x^2 - y^2)$ Get the curve $C$ in $\mathbb{R}^3$ by intersection of paraboloid with the plane $z = g(x, y) = 2x + 4y$. Let the vector field be $F(x, y, z) = (-y, x, z)$ $$\int_C F \cdot \, d\vec{s}$$ To calculate directly, find the equation for the curve $$\begin{aligned} 4 - x^2 - y^2 &= 2x + 4y \\ (x + 1)^2 + (y + 2)^2 &= 9 \end{aligned} $$ Parameterize the curve as follows: $$\begin{aligned} x &= -1 + 3\cos \theta \\ y &= -2 + 3\sin \theta \\ z &= 2(-1 + 3\cos \theta) + 4(-2 + 3\sin \theta) \end{aligned} $$ This is from using the equation of the plane but the same result also comes from using the equation of the paraboloid from $0 \leq \theta \leq 2\pi$. This is positive orientation. It can be done but it's too messy. Stoke's theorem changes this to a surface integral. Let $S$ be the paraboloid. Then $$\begin{aligned} T_x &= (1, 0, \frac{\partial z}{\partial x}) \\ T_y &= (0, 1, \frac{\partial z}{\partial y}) \\ T_x \times T_y &= (-\frac{\partial z}{\partial x}, -\frac{\partial z}{\partial y}, 1) = (2x, 2y, 1) \\ \curl (F) &= (R_y - Q_z, P_z - R_x, Q_x - P_y) = (0, 0, 2) \\ \iint_{\text{paraboloid}} \curl(F) \cdot \, d\vec{s} &= \iint (0, 0, 2) \cdot (2x, 2y, 1) \, dA_{xy}  \end{aligned} $$ Parameterize the part of the paraboloid $S$ that we want by taking $(x, y)$ in the projection of the region in the $xy$ plane, namely $(x + 1)^2 + (y + 2)^2 \leq 9$ Therefore $$\iint 2 \, dA_{xy} = 2 \cdot 9\pi = 18\pi $$ \end{example} 

When the vector field is $\curl(F)$, the line integral $\int_C F \cdot \, d\vec{s}$ only depends on the boundary. Then surface integral $\iint \curl(F) \, d\vec{s}$ doesn't care which surface is being used as long as the boundary is $C$. 

\begin{example} Let $C$ be the closed, piecewise, smooth curve formed by P(-2, 1), Q(-2, -3), R(1, -1), S(1, 5) and back to P(-2, 1), in that order. Use Green's theorem to evaluate the integral $$\int_C 2xy \, dx + xy^2 \, dy $$ 
To do the line integral directly, you have to parameterize each line on the curve $C$. For example, $\overline{PQ} = (-2, 1) + t(0, -4)$ and so $x = -2$ and $y = 1 - 4t$, etc. Instead, use Green's theorem. Then $\iint Q_x - P_y \, dA_{xy}$ over the ``parallelogram'' (including inside) to make a surface a plane. Thus $$\int_{-2}^1 \int y^2 - 2x \, dydx $$
As for the $y$ variable, $y$ goes from line $qr$ where $qr: y - 3 = \frac{2}{3}(x + 2)$ or $y = \frac{2}{3}x - \frac{5}{3}$ to $pr$ where $pr: y = \frac{4}{3}x + \frac{11}{3}$. Thus $$\int_{-2}^1 \int_{\frac{2}{3}x - \frac{5}{3}}^{\frac{4}{3}x + \frac{11}{3}} y^2 - 2x \, dydx = 61 $$ \end{example} 
Return to the conservative vector field. Where is $F = \nabla f$ such that vector field $F$ is a gradient at scalar field $f$? 
\begin{theorem} Let $F$ be a $C^1$ vector field on $\mathbb{R}^3$ (maybe not defined or not $C^1$ on finitely many points in $\mathbb{R}^3$). The following conditions are equivalent: \begin{enumerate} \item For each simple closed curve $C$ in $\mathbb{R}^3$, $\int_C F \cdot \, d\vec{s} = 0$ \item Path independence: For each pair of simple oriented curves $C_1,~C_2$ with some starting point and ending point, $$\int_{C_1} F  \cdot\,  d\vec{s} = \int_{C_2} F \cdot \, d\vec{s} $$ 
\item There is a $C^2$ scalar field $f$ (omitting the exceptional points) such that $F = \nabla f$is a gradient vector field
\item $\curl(F) = (0, 0, 0)$ \end{enumerate} \end{theorem} 

\begin{proof} Assume no bad points. \\
$(1) \to (2)$: Use simple closed curve from $p$ to $q$ to $p$ or $C_1 \cdot C_2^-$. By (1), we get $$\int_{C_1 \cdot C_2^-} F \cdot \, d\vec{s} = 0 $$ Thus $$\int_{C_1} F \cdot \, d\vec{s} + \int_{C_2^-} F \cdot \, d\vec{s} = 0$$ Therefore $$\int_{C_1} F \cdot \, d\vec{s} = -\int_{C_2^-} F \cdot \, d\vec{s} = \int_{C_2} F \cdot \, d\vec{s} $$ 
$(2) \to (3)$: Let $P_0(x_0, y_0, z_0)$ be a fixed point in $\mathbb{R}^3$. Define a scalar field $f$ at gradient point $q(x, y, z)$ by $\int_{p_0}^q F \cdot \, d\vec{s}$ along simple curve from $p_0$ to $q$. By (2), it doesn't matter which path we use to go from $p$ to $q$. Suppose $F = (P, Q, R)$. Strategy: Choose a path that makes $\frac{\partial f}{\partial z}$ easy to compute. Take piecewise linear path $(x_0, y_0, z_0)$ to $(x, y_0, z_0)$ to $(x, y, z_0)$ to $(x, y, z)$. Then $$\begin{aligned} f(q) &= \int F \cdot \, d\vec{s} \\ &= \int P\, dx + Q\, dy + R\, dz \\ &= \int_{x_0}^x \underbrace{P(t, y_0, z_0) \, dt}_{dy = dz = 0} + \int_{y_0}^y \underbrace{Q(x, t, z_0)\, dt}_{dx = dz = 0} + \int_{z_0}^z \underbrace{R(x, y, t) \,dt}_{dx = dy = 0} \end{aligned} $$ Find $\frac{\partial f}{\partial z}$. The derivative of the first two integrals is 0 because there are no $z$s in them. By the Fundamental Theorem of Calculus, the derivative of the last part is $R(x, y, z)$. \\
$(3) \to (4)$: Trivial. Compute $\curl(\nabla f) = \curl(f_x, f_y, f_z) = (0, 0, 0)$ by equality of mixed partials when $f$ is $C^2$ \\
$(4) \to (1)$: If you have a simple curve in $\mathbb{R}^3$, you can fill in a surface $S$ whose boundary is $C$. Then apply Stoke's theorem $$\int_C F \cdot \, d\vec{s} = \iint \underbrace{\curl(F)}_{\nabla \times F} \, d\vec{s} = \iint 0 \, d\vec{s} = 0 $$ \end{proof} 

\begin{example} Evaluate $\iint_S (\nabla \times \vec{F}) \cdot \, d\vec{S}$, where $S$ is the surface $x^2 + y^2 + 3z^2 = 1$, $z \leq 0$ and $\vec{F}$ is the vector field $\vec{F} = y\hat{i} - x\hat{j} + zx^3y^2\hat{k}$. Let $n$, the unit normal, be upward pointing. Solve this using the surface integral and then using Stoke's Theorem. \\ 
(1) $\nabla \times \vec{F} = (2x^3yz, -3x^2y^2z, -2)$. If we think of $z$ as being defined by the equation $x^2 + y^2 + 3z^2 = 1$, then $$\begin{aligned} 2x + 6z\frac{\partial z}{\partial x} &= 0 \\ \frac{\partial z}{\partial x} &= -\frac{x}{3z} \\ \frac{\partial z}{\partial y} &= -\frac{y}{3z} \\ \text{Thus the normal to the graph is } \Big(\frac{\partial g}{\partial x}, \frac{\partial g}{\partial y}, -1\Big) &= \Big(-\frac{x}{3z}, -\frac{y}{3z}, -1) \end{aligned} $$
Here we will use $\Big( \frac{x}{3z}, \frac{y}{3z}, 1 \Big)$. Therefore $$\begin{aligned} \iint_S \nabla \times \vec{F} \cdot \, d\vec{S} &= \iint (2x^3yz, -3x^2y^2z, -2) \cdot (\frac{x}{3z}, \frac{y}{3z}, 1) \, dA_{xy} \\ \iint \frac{2x^4y}{3} - x^2y^3 - 2 \, dA_{xy} \end{aligned} $$ Projection to the $xy$ plane is the unit circle. In addition, the first two integrals are zero by symmetry. Thus $$\iint_S \nabla \times \vec{F} \cdot \, d\vec{S} = -2\iint \, dA_{xy} = -2(\pi(1)^2) = -2\pi $$ 
(2) Stoke's theorem is a ``fundamental theorem of calculus'' in higher dimensions. $$\iint_S \nabla \times \vec{F} \cdot \, d\vec{S} = \int_{\partial S} F \cdot \, ds $$ $S$ is the bottom of the ellipsoid. $\partial S$ is a circle in the $xy$ plane. \\ Implicit parameterization of surface: $\Phi(x, y) = (x, y, -\sqrt{\frac{1 - x^2 - y^2}{3}})$ where do we choose $x,y$ to get the surface we want. $$\int y\,d dx - x \, dy + zx^3y^2 \, dz $$ Note: $\vec{S} = (x, y, z)$, then $d\vec{S} = (dx, dy, dz)$. $\partial S$ is a circle in the $xy$ space and counterclockwise when $z = 0$ $$\int_{\partial S} y\, dx - x\, dy = \int_0^{2\pi} (\sin \theta (-\sin \theta) - (\cos \theta)\cos \theta) \, d\theta = -1 \cdot 2\pi = -2\pi $$ \end{example} 

Another implication of Stoke's theorem is that $\iint \nabla \times \vec{F} \cdot \, d\vec{S} = -2\pi$ on the boundary of a unit circle in the $xy$ plane (with an upward normal). 

To convert $\iint F \cdot \, d\vec{S}$ to a line integral, we need to know whether $F = \nabla \times \vec{G}$ for some conservative field $\vec{G}$. Necessary criterion: $$\nabla \cdot (\nabla \times \vec{G}) = 0 \text{ or } \div(\curl(\vec{G})) = 0 $$ 
using equality of mixed partials where $\vec{G}$ is a $C^2$ function. There is a converse. 

\begin{theorem} If $F$ is $C^1$ on $\mathbb{R}^3$ (no exceptional points) and $\nabla \cdot \vec{F} = 0$, then there is a $\vec{G}$ such that $\vec{F} = \nabla \times \vec{G}$. \end{theorem} 

Note: In general, a vector field $\vec{F}$ can be written as $\vec{F} = \nabla f + (\nabla \times \vec{G}) $. 

\begin{example} Evaluate $\iint_S \nabla \times \vec{F} \cdot \, d\vec{S}$ where $\vec{F} = (x^2 + y - 4)\hat{i} + 3xy\hat{j} + (2xz + z^2)\hat{k}$ and $S$ is the surface $x^2 + y^2 + z^2 = 16$, $z \geq 0$. Let $n$, the unit normal, be upward pointing. \\ 
Stoke's theorem applies and $\partial S$ is a unit circle. To cheat the trigonometry functions, we will parameterize as a graph $(x, y, z(x, y))$ where $(x, y)$ is a unit circle. $$\begin{aligned} \frac{\partial z}{\partial x} &= -\frac{x}{z} \\ \frac{\partial z}{\partial y} &= -\frac{y}{z} \end{aligned}$$ Then the normal is $(-\frac{x}{z}, -\frac{y}{z}, -1)$ Since we want upward normal, the normal is actually $(\frac{x}{z}, \frac{y}{z}, 1)$. $$\begin{aligned} \int_S \nabla \times \vec{F} \cdot \, d\vec{S} &= \iint_{\text{unit disk}} (0, -2z, 3y - 1) \cdot (\frac{x}{z}, \frac{y}{z}, 1) \, dA_{xy} \\ &= \iint_{\text{unit disk}} y - 1 \, dA_{xy} \\ &= -\iint \, dA_{xy} = -(\pi \cdot 1^2) = -\pi \end{aligned} $$ \end{example} 

\begin{theorem} Fundamental Theorem of Calculus for Triple Integrals: Divergence/Gauss's Theorem: $$\iiint_{\text{solid}} \nabla \cdot \vec{F} \, dV = \iint_{\partial W} \vec{F} \cdot \, d\vec{S} $$ \end{theorem}
What is a simple region in $\mathbb{R}^3$ is over where you can set up a triple integral for some ordering of $dx, dy, dz$. 
\begin{example} For $dzdydx$, $\Phi_1(x, y) \leq z \leq \Phi_2(x, y)$, $\phi_1(x) \leq y \leq \phi_2(x)$ and $a \leq x \leq b$. \\ Symmetric elementary regions in $\mathbb{R}^3$ can be set up as a triple integral with all 3 possible choices of innermost differential. \end{example} 
The boundaries are parameterized surfaces, using outward normal as positive orientation. $\vec{F}$ is a $C^1$ vector field on the neighborhood of $W$. 
\begin{example} Let $\vec{F}(x, y, z) = (x, y, z)$ be a radial vector field. Find the flux out of a sphere of radius $R$. $$\begin{aligned} \iint_{\text{sphere}} \vec{F} \cdot \, d\vec{S} &= \iint (x, y, z) \cdot R\sin \phi (x, y, z) \, dA_{\phi, \theta} \\ &= R^3 \int_0^{2\pi} \int_0^{\pi} \sin \phi \, d\phi d\theta \\ &= R^3 \cdot 2 \cdot 2\pi \\ &= 4\pi R^3  \end{aligned} $$ 
Alternative Method: Unit normal to the sphere is $\frac{1}{R}(x, y, z)$. Then $$\iint (\vec{F} \cdot \vec{n}) \, dS = \iint_{\text{sphere}} (x, y, z) \cdot \frac{1}{R}(x, y, z)\, dS = R\iint_{\text{sphere}} \, dS = R \cdot 4\pi R^2 = 4\pi R^3 $$ 
Using Gauss's theorem, $$\begin{aligned} \nabla \times \vec{F} &= \frac{\partial P}{\partial x} + \frac{\partial Q}{\partial y} + \frac{\partial R}{\partial z} = 1 + 1 + 1 = 3 \\ \iiint_{\text{ball of radius }R} 3\, dV &= 3\iiint \, dV = 3 \cdot \frac{4\pi}{3}R^3 = 4\pi R^3 \end{aligned} $$ \end{example} 

\begin{example} Let $T$ be a standard solid tetrahedron. Then $\partial T$ is triangles in the coordinate planes and a slanting plane through $\hat{i}, \hat{j}, \hat{k}$. The equation of this slanting plane is $x + y + z = 1$. The slices parallel to the $xy$ plane are right triangles where its leg is $1 - z$. Thus the area of the triangles are $\frac{1}{2}(1 - z)^2$. Hence the volume of $T$ is $$\int_0^1 \frac{1}{2}(1 - z)^2 \, dz = -\frac{1}{6}(1 - z)^3 \Big|_0^1 = \frac{1}{6} $$ 
Let's say $F = (x, y, z)$, a radial vector field as before. One could do the surface integral on $\partial T$ by parameterizing boundary planes. But what about divergence theorem? $$\nabla \times F = 3 \to \iiint_T 3\, dV = 3 \cdot \frac{1}{6} = \frac{1}{2} $$ 
$xy$ plane: Parameterization: $(x, y, 0)$. Outward normal: $-(T_x \times T_y) = -\hat{k}$
$$\iint F \cdot \, d\vec{S} = \iint (x, y, 0) \cdot (0, 0, -1) \, dS = 0 $$ 
Same result in $yz$ and $xz$ plane. \\ 
Slanted plane: Parameterization: $(x, y, 1 - x - y)$ as a graph $$T_x \times T_y = -(\frac{\partial g}{\partial x}, \frac{\partial g}{\partial y}, -1) = (1, 1, 1) $$ This is normal to the plane! $$\iint (x, y, 1 - x - y) \cdot (1, 1, 1) \, dA_{xy} = \iint \, dA_{xy} $$ $xy$ is in parameterizing right triangle from the $xy$ plane, thus $$\iint \, dA_{xy} = \frac{1}{2}(1)(1) = \frac{1}{2}$$ \end{example}

\begin{example} Compute $\iint_S xy \, dS$, where $S$ is the surface of the tetrahedron with sides $z = 0$, $y = 0$, $x + z = 1$ and $x = y$. \\ 
You need a different parameterization for each triangular face. On the face $z = 0$, make the parameterization $(x, y, 0)$ (on triangular in $xy$ plane). \\
Note: For scalar surface integral, direction of normal does not matter. For vector surface integrals, $d\vec{S} = T_x \times T_y \, dA_{xy} $ where direction matters. For scalar surface integrals, $dS = || T_x \times T_y || \, dA_{xy} $.. \\ On the right side plane through (0, 0, 1), (1, 1, 0) and (0, 0, 0), the normal needed for the equation of the plane is obtained by $(0, 0, 1) \times (1, 1, 0)$ which will yield $x = y$. Thus the parameterization is $(x, x, z)$. Then $dS = ||T_x \times T_y || \, dA_{xy} = \sqrt{2} \, dA_{xy} $ For this plane, the surface integral turns out to be $$\iint_S xy \, dS = \int_0^1 \int_0^{1 - x} x \cdot c \sqrt{2} \, dzdx $$ \end{example} 

\begin{example} Let the velocity field of a fluid be described by $F = \hat{i} + x\hat{j} + z\hat{k}$ (measured in meters per second). Compute how many cubic meters of fluid per second are crossing the surface described by $x^2 + y^2 + z^2 = 1$, $z \geq 0$. \\ 
The surface is a unit hemisphere of radius $r = 1$ centered at (0, 0, 0). This means $\rho = 1$. $$\begin{aligned} x &= \sin \phi \cos \theta \\ y &= \sin \phi \sin \theta \\ z &= \cos \phi \\ d\vec{S} &= \sin \phi (x, y, z) \, dA_{\phi, \theta} \end{aligned} $$ 
Then $$\begin{aligned} \text{Flux} &= \iint_S F \cdot \, d\vec{S} \\ &= \int_0^{2\pi} \int_0^{\frac{\pi}{4}} (1, x, z) \cdot \sin \phi(x, y, z) \, d\phi, d\theta \\ &= \int_0^{2\pi} \int_0^{\frac{\pi}{4}} (x + xy + z^2)\sin \phi \, d\phi d\theta \\ &= \int_0^{2\pi} \int_0^{\frac{\pi}{4}} \sin^2 \phi \cos \theta + \sin^3 \phi \sin \theta \cos \theta + \sin \phi \cos^2 \theta \, d\phi d\theta \\ &= 0 + 0 + 2\pi \int_0^{\frac{\pi}{4}} \sin \phi \cos^2 \phi \, d\phi \\ &= \frac{2}{3}\pi \end{aligned} $$ 
Gauss's Theorem: This theorem applies to closed surfaces that contain finite volume. Therefore, we need to include the disk in the $xy$ plane that was not part of the original problem. Its parameterization is $(x, y, 0)$ where $x^2 + y^2 = 1$. Then $T_x \times T_y \, dA_{xy} = (1, 0, 0) \times (0, 1, 0) \, dA_{xy} = (0, 0, 1) \, dA_{xy} = \hat{k} \, dA_{xy} $. Use $-k \, dA_{xy}$. $$\iint (1, x, 0) \cdot (0, 0, -1) \, dA_{xy} = 0 $$ 
Convert to scalar volume integral. $$\begin{aligned} \iint_S F \cdot \, d\vec{S} &= \iiint_S \nabla \cdot F \, dV \\ &= \iiint 1 \, dV \\ &= 1 \cdot \frac{1}{2} \cdot \frac{4}{3}\pi(1)^3 \\ &= \frac{2}{3}\pi \end{aligned} $$ \end{example} 

In nice situations, we can evaluate $\int_C F \cdot \, d\vec{S} = f(q) - f(p)$. We need $F = \nabla f$ for some $C^1$ scalar function. 

\begin{proof} Let $g = f(\vec{c}(t))$ where $g: [a, b] \to \mathbb{R}$ and $f: $ neighborhood in $\mathbb{R}^3$ of curve $C \to \mathbb{R}$. Its derivative is a $1 \times 3$ gradient vector. Then $g'(t) = \nabla f \cdot \vec{c}'(t)$. Now parameterize the line integral. $$\begin{aligned} \int_C F \cdot \, d\vec{S} &= \int_a^b  F(\vec{c}(t))  \cdot \vec{c}'(t) \, dt \\ &= \int_a^b g'(t) \, dt \\ &= g(t)\Big|_a^b \\ &= f(\vec{c}(b)) - f(\vec{c}(a)) \\ &= f(q) - f(p) \end{aligned} $$ \end{proof} 

\begin{example} Show that $\int_C \frac{x \, dy - y\, dx}{x^2 + y^2} = 2\pi$ where $C$ is the unit circle. \\ Let $F(x, y) = \Big( \frac{-y}{x^2 + y^2}, \frac{x}{x^2 + y^2} \Big)$. Then if $x = \cos \theta$ and $y = \sin \theta$, then $$\begin{aligned} \int_C F \cdot \, (dx, dy) &= \int_C -y \, dx + x \, dy \\ &= \int_0^{2\pi} \sin^2 \theta + \cos^2 \theta \, d\theta \\ &= 2\pi \end{aligned} $$
Conclude that the associated vector field $ -\frac{y}{x^2 + y^2}\hat{i} + \frac{x}{x^2 + y^2} \hat{j}$ is not a conservative vector field. However, $Q_x = P_y$. We know if $G = (P, Q, R) = \nabla g$ is a gradient vector field, then $\curl G = \nabla \times G = 0$. Here we could think of $F$ as $\Big( -\frac{y}{x^2 + y^2}, \frac{x}{x^2 + y^2}, 0 \Big)$. Then $\curl F = (0, 0, 0)$. \end{example} 

\begin{theorem} If $F$ is $C^1$ vector field on all of $\mathbb{R}^2$ except possibly finitely many boundary points and $\curl F = 0$, then there if $f$ such that $F = \nabla f$ where defined. \end{theorem} 
In the previous example, where we embedded $F$ as a vector field in $\mathbb{R}^3$, the function on $x^2 + y^2 = 0$, which is the $z$-axis in $\mathbb{R}^3$, is bad. Integrate $-\frac{y}{x^2 + y^2} \, dx$. This gives $f(x, y, z) = \arctan \frac{y}{x}$. Thus $\frac{\partial f}{\partial x} = \frac{1}{1 + (y/x)^2} \cdot y \cdot -\frac{1}{x^2} = -\frac{y}{1 + x^2} $. If we try to prove for vector fields on $\mathbb{R}^2$ that $Q_x = P_y$, show that $F = \nabla f$. We would like to be on a simply-connected region in $\mathbb{R}^2$. In a simply-connected region $D$: \begin{itemize} \item There is a $C^1$ path or piecewise $C^1$ path between any two points on $D$ \item There are no holes in the region; more specifically, every closed curve can be shrink to a point \end{itemize} Use this idea to show that $\oint_C F \, d\vec{s} = 0$. Using invariance of line integrals independent of path. Once you have this property, you can construct a well-defined $f$ such that $F = \nabla f$. 

\begin{example} Let $W$ be the pyramid with top vertex (0, 0, 1) and base vertices at (0, 0, 0), (1, 0, 0), (0, 1, 0) and (1, 1, 0). Let $S$ be the two-dimensional closed surface bounding $W$, oriented outward from $W$. Use Gauss's theorem to calculate $\iint_S F \cdot \, d\vec{S}$ where $F(x, y, z) = (x^2y, 3y^2z, 9z^2x)$. 
$$\iint_S F \cdot \, d\vec{S} = \iiint_S \nabla \times F \, dV = \iiint_S 2xy + 6yz + 18zx \, dV $$ Let $dV = dy \, dA_{xz}$. Parameterize the right side plane as $y + z = 1$. \\ Alternative method: $$\begin{aligned} ax + by + cz &= d \\ (0, 0, 1) &\to c = d \\ (0, 1, 0) &\to b = d \\ (1, 1, 0) &\to a + b = d \\ (a, b, c, d) = (0, d, d, d) &\to y + z = 1 \end{aligned} $$ $$ \int_0^1 \int_0^{1 - x} \int_0^{1 - z} 2xy + 6yz + 18xz \, dydzdx $$
For the $xz$ plane, parameterize line as $x + z = 1$. \\ 
What about surface integral? In the $xz$ plane, $y = 0$. Then a parameterization is $(x, 0, z)$ where $T_x = (1, 0, 0)$, $T_y = (0, 0, 1)$ and $T_x \times T_y = (0, -1, 0)$. Then $$\iint (0, 0, 9z^2x) \cdot (0, -1, 0) \, dA_{xy} = 0 $$ \end{example} 

\begin{example} The mapping $T(u, v) = (u^2 - v^2, 2uv)$ transforms the rectangle $1 \leq u \leq 2$, $1 \leq v \leq 3$ of the $uv$ plane into a region $R$ of the $xy$ plane. Show that $T$ is one-to-one and find the area of $R$ using the change of variables formula. \\ 
To check, if $T(u_1, v_1) = T(u_2, v_2)$, then $u_1 = u_2$ and $v_1 = v_2$. $$\begin{aligned} 2u_1v_1 &= 2u_2v_2 \\ v_2 &= \frac{u_1}{u_2}v_1 \\ (u_2^2 - u_1^2)(u_2^2 + v_1^2) &= 0 \\ u_2^2 - u_1^2 &= 0 \\ u_1 &= u_2 \end{aligned} $$ 
$$\begin{aligned} \iint_D f(x,y) \, dydx &= \iint_{D^*} f(u^2 - v^2, 2uv) \Big| \det \begin{pmatrix} 2u & -2v \\ 2v & 2u \end{pmatrix} \Big| \, dudv \\ &= \iint_{D^*} f(u^2 - v^2, 2uv) \cdot 4(u^2 + v^2) \, dudv \end{aligned} $$ \end{example} 

On a nice region, if $F = \nabla f$, then $\nabla \times F = 0$. If $F = \nabla \times G$, then $\nabla \cdot F = 0$. To find $G$, do integrals. 

\begin{example} Prove: If $F$ is a $C^1$ vector field on all of $\mathbb{R}^3$ with $\div F = 0$, then there exists a $C^1$ vector field $G$ with $F = \curl G$. Define $G = G_1\hat{i}  + G_2\hat{j} + G_3\hat{k}$ \\
Suppose $F = (P, Q, R)$. Let $G_3 = 0$. Then $$\begin{aligned} G_2 &= -\int_{z_0}^z P(x, y, t) \, dt \\ G_1 &= \int_{z_0}^z Q(x, y, t) \, dt - \int_{y_0}^y R(x, t, z_0) \, dt \end{aligned} $$ \end{example} 







\end{document}





